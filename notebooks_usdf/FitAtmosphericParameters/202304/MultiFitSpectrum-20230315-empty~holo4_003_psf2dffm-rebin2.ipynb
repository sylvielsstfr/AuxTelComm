{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MultiFit atmospheric parameters - No Filter date 2023/03/15 PSF2DFFM REBIN2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- author Sylvie Dagoret-Campagne\n",
    "- affiliation : IJCLab/IN2P3/CNRS\n",
    "- creation date : April 14th 2023\n",
    "- last update : April 16th 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Multi fit means pwv may be fitted in several bands independently"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm as cm \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "import numpy as np\n",
    "from mpl_toolkits.axes_grid1 import host_subplot\n",
    "import mpl_toolkits.axisartist as AA\n",
    "import os,sys,re\n",
    "\n",
    "from astropy.io import fits\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.cm as cmx\n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib import gridspec\n",
    "%matplotlib inline\n",
    "import pickle\n",
    "import h5py\n",
    "import seaborn as sns\n",
    "import copy\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('./lib')\n",
    "from libAtmosphericFit import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.offsetbox\n",
    "props = dict(boxstyle='round',edgecolor=\"w\",facecolor=\"w\", alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to enlarge the sizes\n",
    "params = {'legend.fontsize': 'x-large',\n",
    "          'figure.figsize': (10, 6),\n",
    "         'axes.labelsize': 'xx-large',\n",
    "         'axes.titlesize':'xx-large',\n",
    "         'xtick.labelsize':'xx-large',\n",
    "         'ytick.labelsize':'xx-large'}\n",
    "plt.rcParams.update(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pysynphot_root_path=os.environ['PYSYN_CDBS']\n",
    "path_sed_calspec=os.path.join(pysynphot_root_path,'calspec')\n",
    "# pysynphot\n",
    "import pysynphot as S\n",
    "S.refs.setref(area=1)\n",
    "S.refs.getref()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from datetime import datetime,date\n",
    "from astropy.time import Time\n",
    "import dateutil.parser\n",
    "import pytz\n",
    "\n",
    "import argparse\n",
    "\n",
    "import logging\n",
    "import coloredlogs\n",
    "import configparser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import interpolate\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.signal import savgol_filter\n",
    "from scipy import fftpack\n",
    "from scipy.optimize import curve_fit,least_squares\n",
    "from scipy.interpolate import RegularGridInterpolator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libradtran\n",
    "sys.path.append('../../../simulation/atmsim/libradtran')\n",
    "import libsimulateVisible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from atmosphtransmemullsst.simpleatmospherictransparencyemulator import SimpleAtmEmulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from spectractor.extractor.spectroscopy import Lines, Line ,HALPHA, HBETA, O2_1, H2O_1, ATMOSPHERIC_LINES\n",
    "\n",
    "class Line:\n",
    "    \"\"\"Class modeling the emission or absorption lines.\"\"\"\n",
    "\n",
    "    def __init__(self, wavelength, label, atmospheric=False, emission=False, label_pos=[0.007, 0.02],\n",
    "                 width_bounds=[0.5, 6], use_for_calibration=False):\n",
    "        \"\"\"Class modeling the emission or absorption lines. lines attributes contains main spectral lines\n",
    "        sorted in wavelength.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        wavelength: float\n",
    "            Wavelength of the spectral line in nm\n",
    "        label: str\n",
    "\n",
    "        atmospheric: bool\n",
    "            Set True if the spectral line is atmospheric (default: False)\n",
    "        emission: bool\n",
    "            Set True if the spectral line has to be detected in emission. Can't be true if the line is atmospheric.\n",
    "            (default: False)\n",
    "        label_pos: [float, float]\n",
    "            Position of the label in the plot with respect to the vertical lin (default: [0.007,0.02])\n",
    "        width_bounds: [float, float]\n",
    "            Minimum and maximum width (in nm) of the line for fitting procedures (default: [1,7])\n",
    "        use_for_calibration: bool\n",
    "            Use this line for the dispersion relation calibration, bright line recommended (default: False)\n",
    "\n",
    "        Examples\n",
    "        --------\n",
    "        >>> l = Line(550, label='test', atmospheric=True, emission=True)\n",
    "        >>> print(l.wavelength)\n",
    "        550\n",
    "        >>> print(l.label)\n",
    "        test\n",
    "        >>> print(l.atmospheric)\n",
    "        True\n",
    "        >>> print(l.emission)\n",
    "        False\n",
    "        \"\"\"\n",
    "        self.wavelength = wavelength  # in nm\n",
    "        self.label = label\n",
    "        self.label_pos = label_pos\n",
    "        self.atmospheric = atmospheric\n",
    "        self.emission = emission\n",
    "        if self.atmospheric:\n",
    "            self.emission = False\n",
    "        self.width_bounds = width_bounds\n",
    "        self.fitted = False\n",
    "        self.use_for_calibration = use_for_calibration\n",
    "        self.high_snr = False\n",
    "        self.fit_lambdas = None\n",
    "        self.fit_gauss = None\n",
    "        self.fit_bgd = None\n",
    "        self.fit_snr = None\n",
    "        self.fit_fwhm = None\n",
    "        self.fit_popt = None\n",
    "        self.fit_pcov = None\n",
    "        self.fit_popt_gaussian = None\n",
    "        self.fit_pcov_gaussian = None\n",
    "        self.fit_chisq = None\n",
    "        self.fit_eqwidth_mod = None\n",
    "        self.fit_eqwidth_data = None\n",
    "        #self.fit_bgd_npar = parameters.CALIB_BGD_NPARAMS\n",
    "        self.fit_bgd_npar = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HALPHA = Line(656.3, atmospheric=False, label='$H\\\\alpha$', label_pos=[-0.01, 0.02], use_for_calibration=True)\n",
    "HBETA = Line(486.3, atmospheric=False, label='$H\\\\beta$', label_pos=[0.001, 0.02], use_for_calibration=True)\n",
    "HGAMMA = Line(434.0, atmospheric=False, label='$H\\\\gamma$', label_pos=[0.001, 0.02], use_for_calibration=True)\n",
    "HDELTA = Line(410.2, atmospheric=False, label='$H\\\\delta$', label_pos=[0.001, 0.02], use_for_calibration=True)\n",
    "HEPSILON = Line(397.0, atmospheric=False, label='$H\\\\epsilon$', label_pos=[0.001, 0.02], use_for_calibration=True)\n",
    "\n",
    "HZETA = Line(388.9064, atmospheric=False, label='$H\\\\zeta$', label_pos=[0.001, 0.02], use_for_calibration=False)\n",
    "HETA = Line(383.5397, atmospheric=False, label='$H\\\\eta$', label_pos=[0.001, 0.02], use_for_calibration=False)\n",
    "\n",
    "HBETA2 = Line(486.3*2, atmospheric=False, label='$H\\\\beta$2', label_pos=[0.001, 0.02], use_for_calibration=True)\n",
    "HGAMMA2 = Line(434.0*2, atmospheric=False, label='$H\\\\gamma$2', label_pos=[0.001, 0.02], use_for_calibration=True)\n",
    "HDELTA2 = Line(410.2*2, atmospheric=False, label='$H\\\\delta$2', label_pos=[0.001, 0.02], use_for_calibration=True)\n",
    "HEPSILON2 = Line(397.0*2, atmospheric=False, label='$H\\\\epsilon$2', label_pos=[0.001, 0.02], use_for_calibration=True)\n",
    "HZETA2 = Line(388.9064*2, atmospheric=False, label='$H\\\\zeta$2', label_pos=[0.001, 0.02], use_for_calibration=False)\n",
    "HETA2 = Line(383.5397*2, atmospheric=False, label='$H\\\\eta$2', label_pos=[0.001, 0.02], use_for_calibration=False)\n",
    "\n",
    "O2_1 = Line(760.3, atmospheric=True, label='$O_2$',label_pos=[0.001, 0.02], use_for_calibration=True)  # libradtran paper fig.3\n",
    "O2_2 = Line(763.1, atmospheric=True, label='$O_2$',label_pos=[0.001, 0.02], use_for_calibration=True)  # libradtran paper fig.3\n",
    "\n",
    "O2B = Line(687.472, atmospheric=True, label=r'$O_2(B)$',  # 687.472 is a weighted average of the O2B line simulated by Libradtran\n",
    "           label_pos=[0.001, 0.02], use_for_calibration=True)  # https://en.wikipedia.org/wiki/Fraunhofer_lines\n",
    "O2Y = Line(898.765, atmospheric=True, label=r'$O_2(Y)$',\n",
    "           label_pos=[0.001, 0.02])  # https://en.wikipedia.org/wiki/Fraunhofer_lines\n",
    "O2Z = Line(822.696, atmospheric=True, label=r'$O_2(Z)$',\n",
    "           label_pos=[0.001, 0.02])  # https://en.wikipedia.org/wiki/Fraunhofer_lines\n",
    "# H2O = Line( 960,atmospheric=True,label='$H_2 O$',label_pos=[0.007,0.02],width_bounds=(1,50))  #\n",
    "H2O_1 = Line(935, atmospheric=True, label=r'$H_2 O$', label_pos=[0.001, 0.02],  # MFL: don't these need different labels?\n",
    "             width_bounds=[5, 30])  # libradtran paper fig.3, broad line\n",
    "H2O_2 = Line(960, atmospheric=True, label=r'$H_2 O$', label_pos=[0.001, 0.02],  # MFL: don't these need different labels?\n",
    "              width_bounds=[5, 30])  # libradtran paper fig.3, broad line\n",
    "ATMOSPHERIC_LINES = [O2_1, O2_2, O2B, O2Y, O2Z, H2O_1]\n",
    "\n",
    "\n",
    "H2O_1 = Line(935, atmospheric=True, label=r'$H_2 O$', label_pos=[0.001, 0.02],  # MFL: don't these need different labels?\n",
    "             width_bounds=[5, 30])  # libradtran paper fig.3, broad line\n",
    "H2O_2 = Line(960, atmospheric=True, label=r'$H_2 O$', label_pos=[0.007, 0.02],width_bounds=[5, 30])  # libradtran paper fig.3, broad line\n",
    "\n",
    "#my_calib_lines_etador = Lines([HALPHA,HBETA,HGAMMA,HDELTA,HEPSILON,HBETA2,HGAMMA2,HDELTA2,HEPSILON2,HZETA2,O2_1,O2_2],hydrogen_only=True,atmospheric_lines=True, redshift=0, emission_spectrum=False)\n",
    "#hydrogen_lines_order1 =  Lines([HALPHA,HBETA,HGAMMA,HDELTA,HEPSILON])\n",
    "#hydrogen_lines_order2 =  Lines([HBETA2,HGAMMA2,HDELTA2,HEPSILON2,HZETA2,HETA2])\n",
    "#oxygen_lines_order1 = Lines([O2_1,O2_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ax.plot([x_O2_1,x_O2_1],[72,100],'b-',lw=3)\n",
    "#ax.annotate(O2_1.label, xy=(x_O2_1, 80), color='b',fontsize=20,fontweight='bold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getenv(\"PYSYN_CDBS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_calspec = os.path.join(os.getenv(\"PYSYN_CDBS\"),\"calspec\")\n",
    "   \n",
    "dict_sedfilename = {'HD38666': \"mucol_stis_005.fits\", \n",
    "            'HD185975': \"hd185975_stis_003.fits\",\n",
    "            'HD074000': \"hd074000_stis_003.fits\",\n",
    "            'HD60753' : \"hd60753_stis_003.fits\",\n",
    "            'HD111980': \"hd111980_stis_003.fits\",\n",
    "            'HD37962':  \"hd37962_stis_005.fits\",\n",
    "            'HD031128' : \"hd031128_stis_005.fits\",\n",
    "            'HD14943' : \"hd14943_stis_005.fits\",\n",
    "            'HD38949' : \"hd38949_stis_005.fits\",\n",
    "            'HD60753' : \"hd60753_stis_004.fits\",\n",
    "             'HD200654': \"hd200654_stis_006.fits\",  \n",
    "             'HD115169': \"hd115169_stis_003.fits\",\n",
    "             'HD142331': \"hd142331_stis_004.fits\", \n",
    "             'HD167060': \"hd167060_stis_004.fits\", \n",
    "              }         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Must divide the observed flux by this correction area\n",
    "correction_area = 1.06/1.13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- filtering here\n",
    "\n",
    "https://stackoverflow.com/questions/20618804/how-to-smooth-a-curve-in-the-right-way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth_data_convolve_my_average(arr, span):\n",
    "    re = np.convolve(arr, np.ones(span * 2 + 1) / (span * 2 + 1), mode=\"same\")\n",
    "\n",
    "    # The \"my_average\" part: shrinks the averaging window on the side that \n",
    "    # reaches beyond the data, keeps the other side the same size as given \n",
    "    # by \"span\"\n",
    "    re[0] = np.average(arr[:span])\n",
    "    for i in range(1, span + 1):\n",
    "        re[i] = np.average(arr[:i + span])\n",
    "        re[-i] = np.average(arr[-i - span:])\n",
    "    return re\n",
    "\n",
    "def smooth_data_np_average(arr, span):  # my original, naive approach\n",
    "    return [np.average(arr[val - span:val + span + 1]) for val in range(len(arr))]\n",
    "\n",
    "def smooth_data_np_convolve(arr, span):\n",
    "    return np.convolve(arr, np.ones(span * 2 + 1) / (span * 2 + 1), mode=\"same\")\n",
    "\n",
    "def smooth_data_np_cumsum_my_average(arr, span):\n",
    "    cumsum_vec = np.cumsum(arr)\n",
    "    moving_average = (cumsum_vec[2 * span:] - cumsum_vec[:-2 * span]) / (2 * span)\n",
    "\n",
    "    # The \"my_average\" part again. Slightly different to before, because the\n",
    "    # moving average from cumsum is shorter than the input and needs to be padded\n",
    "    front, back = [np.average(arr[:span])], []\n",
    "    for i in range(1, span):\n",
    "        front.append(np.average(arr[:i + span]))\n",
    "        back.insert(0, np.average(arr[-i - span:]))\n",
    "    back.insert(0, np.average(arr[-2 * span:]))\n",
    "    return np.concatenate((front, moving_average, back))\n",
    "\n",
    "def smooth_data_lowess(arr, span):\n",
    "    x = np.linspace(0, 1, len(arr))\n",
    "    return sm.nonparametric.lowess(arr, x, frac=(5*span / len(arr)), return_sorted=False)\n",
    "\n",
    "def smooth_data_kernel_regression(arr, span):\n",
    "    # \"span\" smoothing parameter is ignored. If you know how to \n",
    "    # incorporate that with kernel regression, please comment below.\n",
    "    kr = KernelReg(arr, np.linspace(0, 1, len(arr)), 'c')\n",
    "    return kr.fit()[0]\n",
    "\n",
    "def smooth_data_savgol_0(arr, span):  \n",
    "    return savgol_filter(arr, span * 2 + 1, 0)\n",
    "\n",
    "def smooth_data_savgol_1(arr, span):  \n",
    "    return savgol_filter(arr, span * 2 + 1, 1)\n",
    "\n",
    "def smooth_data_savgol_2(arr, span):  \n",
    "    return savgol_filter(arr, span * 2 + 1, 2)\n",
    "\n",
    "def smooth_data_fft(arr, span):  # the scaling of \"span\" is open to suggestions\n",
    "    w = fftpack.rfft(arr)\n",
    "    spectrum = w ** 2\n",
    "    cutoff_idx = spectrum < (spectrum.max() * (1 - np.exp(-span / 2000)))\n",
    "    w[cutoff_idx] = 0\n",
    "    return fftpack.irfft(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def atmpatt_Dataf_to_np(df):\n",
    "    \"\"\"\n",
    "    \n",
    "    atmpatt_Dataf_to_np : convert pandas dtaframe on abs pattern into numpy array\n",
    "    \n",
    "    \"\"\"\n",
    "    o2_cols = []\n",
    "    for tabcol in df.columns:\n",
    "        if 'o2_' in tabcol and 'no2_' not in tabcol:\n",
    "            o2_cols.append(tabcol)\n",
    "            \n",
    "    no2_cols = []\n",
    "    for tabcol in df.columns:\n",
    "        if 'no2_' in tabcol:\n",
    "            no2_cols.append(tabcol)\n",
    "            \n",
    "            \n",
    "    h2o_cols = []\n",
    "    for tabcol in df.columns:\n",
    "        if 'h2o_' in tabcol:\n",
    "            h2o_cols.append(tabcol)\n",
    "            \n",
    "            \n",
    "    o3_cols = []\n",
    "    for tabcol in df.columns:\n",
    "        if 'o3_' in  tabcol:\n",
    "            o3_cols.append(tabcol)\n",
    "            \n",
    "            \n",
    "    data_wl = df[\"wl\"].to_numpy()\n",
    "    data_o2 = df[o2_cols].to_numpy()\n",
    "    data_o3 = df[o3_cols].to_numpy()\n",
    "    data_h2o = df[h2o_cols].to_numpy()\n",
    "    data_no2 = df[no2_cols].to_numpy()\n",
    "    \n",
    "    \n",
    "    return data_wl, data_o2, data_o3, data_h2o, data_no2\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nearest(a, a0):\n",
    "    \"Element in nd array `a` closest to the scalar value `a0`\"\n",
    "    idx = np.abs(a - a0).argmin()\n",
    "    return a.flat[idx],int(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetSpectra(dict_spectra,factor=1.):\n",
    "    \"\"\"\n",
    "    GetSpectra(dict_spectra)\n",
    "    \n",
    "    input:\n",
    "      - dict_spectra : dictionnary of input spectra\n",
    "      \n",
    "      \n",
    "      {'number': 238.0, 'object': 'mu. Col', 'dateobs': '2022-03-18T00:51:22.049', 'refhour': 0.0, 'airmass': 1.11557476948966, 'pressure': 743.45, 'temperature': 8.9, \n",
    "      'humidity': 48.0, 'targetx_pix': 312.7442668572934, 'targety_pix': 1738.0006619324693, 'rotangle': 0.1753951396614214, 'd2ccd': 181.0974436798836, \n",
    "      'all_lambdas': array([ 302.20970512,  302.91544585,  303.62117594, ..., 1108.67461764,\n",
    "       1109.35162338, 1110.02859124]), 'all_fluxes': array([1.04110833e-13, 9.83856109e-14, 8.99209206e-14, ...,\n",
    "       5.34113538e-13, 5.36905940e-13, 5.53127394e-13]), 'all_fluxes_err': array([3.51303583e-15, 3.10100695e-15, 2.58677333e-15, ...,\n",
    "       3.34568263e-15, 4.01784054e-15, 4.54242555e-15]), 'all_lambdas_order2': array([ 302.24857475,  302.9543149 ,  303.66004442, ..., 1108.71192607,\n",
    "       1109.38892974, 1110.06589555]), 'all_fluxes_order2': array([420.23653349, 386.95227531, 344.90384603, ...,  60.47440612,\n",
    "        60.74615545,  62.53491353]), 'all_fluxes_err_order2': array([14.15542468, 12.17674916,  9.90751987, ...,  0.37846535,\n",
    "        0.45415764,  0.51307916])}\n",
    "      \n",
    "    \n",
    "    return\n",
    "      - list of dataframes\n",
    "    \"\"\"\n",
    "    \n",
    "    #correction_area = 1.06/1.13\n",
    "    correction_area = 1\n",
    "    \n",
    "    list_of_columns = [\"number\",\"object\",'dateobs','refhour','airmass','pressure','temperature','humidity','filename','targetx_pix', 'targety_pix','rotangle', 'd2ccd']   \n",
    "\n",
    "    all_df = []  # container for spectra\n",
    "    \n",
    "    df_info = pd.DataFrame(columns=list_of_columns)\n",
    "    \n",
    "    idx=0\n",
    "    sorted_dict_spectra_items = sorted(dict_spectra.items())\n",
    "    for key, value in sorted_dict_spectra_items:\n",
    "        \n",
    "        df_info.loc[idx] = [int(value[\"number\"]),value[\"object\"],value[\"dateobs\"],value[\"refhour\"],value[\"airmass\"],value[\"pressure\"],value[\"temperature\"],value[\"humidity\"],key,value['targetx_pix'],value['targety_pix'],value['rotangle'], value['d2ccd']]\n",
    "         \n",
    "        df = pd.DataFrame()\n",
    "        df[\"all_lambdas\"] = value[\"all_lambdas\"]\n",
    "        df[\"all_fluxes\"] = value[\"all_fluxes\"]/ correction_area*factor \n",
    "        df[\"all_fluxes_err\"] = value[\"all_fluxes_err\"]*factor\n",
    "        \n",
    "        if 'all_lambdas_order2' in value.keys():\n",
    "            df[\"all_lambdas_order2\"] = value[\"all_lambdas_order2\"]\n",
    "            df[\"all_fluxes_order2\"] = value[\"all_fluxes_order2\"]/ correction_area*factor \n",
    "            df[\"all_fluxes_err_order2\"] = value[\"all_fluxes_err_order2\"]*factor\n",
    "            \n",
    "        \n",
    "        all_df.append(df)\n",
    "        \n",
    "        \n",
    "        idx+=1\n",
    "        \n",
    "    return df_info , all_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetColumnHfData(h5spectra,list_of_keys,nameval):\n",
    "    \"\"\"\n",
    "    Extract h5file atttribute \n",
    "    \n",
    "    parameters\n",
    "      hf           : descriptor of h5 file\n",
    "      list_of_keys : list of exposures\n",
    "      nameval      : name of the attribute\n",
    "      \n",
    "    return\n",
    "      the array of values in the order of \n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    all_data = []\n",
    "    for key in list_of_keys:\n",
    "        group=h5spectra.get(key)\n",
    "        val=group.attrs[nameval]\n",
    "        all_data.append(val)\n",
    "    return all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reorder(df,all_subgroup_keys):\n",
    "    \n",
    "    if 'me_az_rms' in all_subgroup_keys:\n",
    "        df = df.reindex(columns=['index',\n",
    "                         'exposure',\n",
    "                         'spec_date_obs',\n",
    "                         'spec_target_label','spec_filter_label',\n",
    "                         'spec_airmass',\n",
    "                         'spec_pressure',\n",
    "                         'spec_temperature',\n",
    "                         'spec_humidity',\n",
    "                         'spec_hour_angle',\n",
    "                         'spec_parallactic_angle',\n",
    "                         'spec_camera_angle',\n",
    "                         'spec_order',\n",
    "                         \"spec_header_target\",\n",
    "                         \"spec_header_redshift\",\n",
    "                         \"spec_header_grating\",\n",
    "                         \"spec_header_rotangle\",\n",
    "                         \"spec_header_d2ccd\",\n",
    "                         \"spec_header_lshift\",\n",
    "                         \"spec_header_parangle\",\n",
    "                         \"spec_header_targetx\",\n",
    "                         \"spec_header_targety\",\n",
    "                         \"spec_header_lbda_ref\",\n",
    "                         \"spec_header_pixshift\",\n",
    "                         \"spec_header_psf_reg\",\n",
    "                         \"spec_header_trace_r\",  \n",
    "                         \"spec_header_chi2_fit\", \n",
    "                         \"spec_header_a2_fit\",\n",
    "                         \"spec_header_am_fit\",\n",
    "                         \"spec_header_meanfwhm\",\n",
    "                         \"spec_header_version\",\n",
    "                         \"spec_header_rebin\",\n",
    "                         \"spec_header_date-obs\",\n",
    "                         \"spec_header_exptime\",\n",
    "                         \"spec_header_airmass\",\n",
    "                         \"spec_header_dec\",\n",
    "                         \"spec_header_ha\",\n",
    "                         \"spec_header_outtemp\",\n",
    "                         \"spec_header_outpress\",\n",
    "                         \"spec_header_outhum\",\n",
    "                         \"spec_header_filter\",\n",
    "                         \"spec_header_cam_rot\",\n",
    "                         \"spec_header_s_x0\",\n",
    "                         \"spec_header_s_y0\",\n",
    "                         \"spec_header_s_xmin\",    \n",
    "                         \"spec_header_s_xmax\",                                             \n",
    "                         \"spec_header_s_ymin\",    \n",
    "                         \"spec_header_s_ymax\",                                                                                                                \n",
    "                         \"spec_header_s_nx\",\n",
    "                         \"spec_header_s_ny\",\n",
    "                         \"spec_header_s_dec\",\n",
    "                         \"spec_header_s_sat\",\n",
    "                         \"spec_spectrogram_x0\",\n",
    "                         \"spec_spectrogram_y0\",\n",
    "                         \"spec_spectrogram_xmin\",\n",
    "                         \"spec_spectrogram_xmax\",\n",
    "                         \"spec_spectrogram_ymin\",\n",
    "                         \"spec_spectrogram_ymax\",\n",
    "                         \"spec_spectrogram_deg\",\n",
    "                         \"spec_spectrogram_saturation\",    \n",
    "                         \"spec_spectrogram_Nx\",\n",
    "                         \"spec_spectrogram_Ny\",\n",
    "                         \"me_az_rms\",\n",
    "                         \"me_el_rms\",\n",
    "                         \"me_rot_rms\",\n",
    "                         \"me_image_az_rms\",\n",
    "                         \"me_image_el_rms\",\n",
    "                         \"me_image_rot_rms\",\n",
    "                        ])\n",
    "    else:\n",
    "        df = df.reindex(columns=['index',\n",
    "                         'exposure',\n",
    "                         'spec_date_obs',\n",
    "                         'spec_target_label','spec_filter_label',\n",
    "                         'spec_airmass',\n",
    "                         'spec_pressure',\n",
    "                         'spec_temperature',\n",
    "                         'spec_humidity',\n",
    "                         'spec_hour_angle',\n",
    "                         'spec_parallactic_angle',\n",
    "                         'spec_camera_angle',\n",
    "                         'spec_order',\n",
    "                         \"spec_header_target\",\n",
    "                         \"spec_header_redshift\",\n",
    "                         \"spec_header_grating\",\n",
    "                         \"spec_header_rotangle\",\n",
    "                         \"spec_header_d2ccd\",\n",
    "                         \"spec_header_lshift\",\n",
    "                         \"spec_header_parangle\",\n",
    "                         \"spec_header_targetx\",\n",
    "                         \"spec_header_targety\",\n",
    "                         \"spec_header_lbda_ref\",\n",
    "                         \"spec_header_pixshift\",\n",
    "                         \"spec_header_psf_reg\",\n",
    "                         \"spec_header_trace_r\",  \n",
    "                         \"spec_header_chi2_fit\", \n",
    "                         \"spec_header_a2_fit\",\n",
    "                         \"spec_header_am_fit\",\n",
    "                         \"spec_header_meanfwhm\",\n",
    "                         \"spec_header_version\",\n",
    "                         \"spec_header_rebin\",\n",
    "                         \"spec_header_date-obs\",\n",
    "                         \"spec_header_exptime\",\n",
    "                         \"spec_header_airmass\",\n",
    "                         \"spec_header_dec\",\n",
    "                         \"spec_header_ha\",\n",
    "                         \"spec_header_outtemp\",\n",
    "                         \"spec_header_outpress\",\n",
    "                         \"spec_header_outhum\",\n",
    "                         \"spec_header_filter\",\n",
    "                         \"spec_header_cam_rot\",\n",
    "                         \"spec_header_s_x0\",\n",
    "                         \"spec_header_s_y0\",\n",
    "                         \"spec_header_s_xmin\",    \n",
    "                         \"spec_header_s_xmax\",                                             \n",
    "                         \"spec_header_s_ymin\",    \n",
    "                         \"spec_header_s_ymax\",                                                                                                                \n",
    "                         \"spec_header_s_nx\",\n",
    "                         \"spec_header_s_ny\",\n",
    "                         \"spec_header_s_dec\",\n",
    "                         \"spec_header_s_sat\",\n",
    "                         \"spec_spectrogram_x0\",\n",
    "                         \"spec_spectrogram_y0\",\n",
    "                         \"spec_spectrogram_xmin\",\n",
    "                         \"spec_spectrogram_xmax\",\n",
    "                         \"spec_spectrogram_ymin\",\n",
    "                         \"spec_spectrogram_ymax\",\n",
    "                         \"spec_spectrogram_deg\",\n",
    "                         \"spec_spectrogram_saturation\",    \n",
    "                         \"spec_spectrogram_Nx\",\n",
    "                         \"spec_spectrogram_Ny\",\n",
    "                        ])\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetSpectraH5(h5spectra,factor=1.):\n",
    "    \"\"\"\n",
    "    GetSpectraH5(dict_spectra)\n",
    "    \n",
    "    input:\n",
    "      h5spectra h5 file descriptor\n",
    " \n",
    "    \n",
    "    return\n",
    "      - list of dataframes\n",
    "    \"\"\"\n",
    "    \n",
    "    # indexes in H5 file\n",
    "    list_of_keys = list(h5spectra.keys())\n",
    "    sorted_spectra_keys = sorted(list_of_keys)\n",
    "    \n",
    "    # pick one key    \n",
    "    key_sel =  sorted_spectra_keys[0]\n",
    "    # pick one group\n",
    "    group = h5spectra.get(key_sel)\n",
    "    \n",
    "    #pickup all attribute names\n",
    "    all_subgroup_keys = []\n",
    "    for k in group.attrs.keys():\n",
    "        all_subgroup_keys.append(k)  \n",
    "        \n",
    "\n",
    "    # create info\n",
    "    df_info = pd.DataFrame()\n",
    "    for key in all_subgroup_keys:\n",
    "        arr=GetColumnHfData(hf, sorted_spectra_keys ,key)\n",
    "        df_info[key] = arr\n",
    "    \n",
    "    df_info = reorder(df_info,all_subgroup_keys)\n",
    "    \n",
    "    \n",
    "    #correction_area = 1.06/1.13\n",
    "    correction_area = 1\n",
    "\n",
    "    all_df = []  # container for spectra\n",
    "    \n",
    "    #d = h5group.create_dataset(\"spec_lambdas\",data=spec.lambdas,compression=\"gzip\", compression_opts=9)\n",
    "    #d = h5group.create_dataset(\"spec_data\",data=spec.data,compression=\"gzip\", compression_opts=9)\n",
    "    #d = h5group.create_dataset(\"spec_err\",data=spec.err,compression=\"gzip\", compression_opts=9)\n",
    "    #d = h5group.create_dataset(\"spec_covmatrix\",data=spec.cov_matrix,compression=\"gzip\", compression_opts=9)\n",
    "    #d = h5group.create_dataset(\"spec_data_next_order\",data=spec.data_next_order,compression=\"gzip\", compression_opts=9)\n",
    "    #d = h5group.create_dataset(\"spec_err_next_order\",data=spec.err_next_order,compression=\"gzip\", compression_opt\n",
    "    \n",
    "    idx=0\n",
    "    for key in sorted_spectra_keys :\n",
    "        \n",
    "        group = h5spectra.get(key)\n",
    "               \n",
    "        df = pd.DataFrame()\n",
    "        data_next_order=  np.array(group.get(\"spec_data_next_order\"))\n",
    "        \n",
    "        df[\"all_lambdas\"] = np.array(group.get(\"spec_lambdas\"))\n",
    "        df[\"all_fluxes\"] = np.array(group.get(\"spec_data\")) / correction_area*factor \n",
    "        df[\"all_fluxes_err\"] = np.array(group.get(\"spec_err\")) /correction_area*factor\n",
    "        \n",
    "        \n",
    "        df[\"all_lambdas_order2\"] = np.array(group.get(\"spec_lambdas\"))\n",
    "        df[\"all_fluxes_order2\"] = np.array(group.get(\"spec_data_next_order\"))/ correction_area*factor \n",
    "        df[\"all_fluxes_err_order2\"] = np.array(group.get(\"spec_err_next_order\"))/ correction_area*factor \n",
    "        \n",
    "        all_df.append(df)\n",
    "        \n",
    "        idx+=1\n",
    "        \n",
    "    return df_info , all_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetSpectraFiltered(dict_spectra,list_of_bad_spectra,factor = 1.):\n",
    "    \"\"\"\n",
    "    GetSpectraFiltered(inputdir,inputfiles)\n",
    "    \n",
    "    input:\n",
    "      - dict_spectra\n",
    "      - ist_of_bad_spectra\n",
    "    \n",
    "    return\n",
    "      - filtered infos, filtered spectra\n",
    "    \"\"\"\n",
    "    \n",
    "    # factor to correct fluxes (over estimated collection surface)\n",
    "    #correction_area = 1.06/1.13\n",
    "    correction_area = 1\n",
    "    \n",
    "    \n",
    "    \n",
    "    list_of_columns = [\"number\",\"object\",'dateobs','refhour','airmass','pressure','temperature','humidity','filename','targetx_pix', 'targety_pix','rotangle', 'd2ccd']   \n",
    "        \n",
    "\n",
    "    all_df = []  # container for spectra\n",
    "    \n",
    "    df_info = pd.DataFrame(columns=list_of_columns)\n",
    "    \n",
    "    idx=0       # counter on input spectra\n",
    "    idx_out = 0 # counter on save spectra\n",
    "    #for key, value in dict_spectra.items():\n",
    "    sorted_dict_spectra_items = sorted(dict_spectra.items())\n",
    "    for key, value in sorted_dict_spectra_items:\n",
    "        \n",
    "        \n",
    "        if int(value[\"number\"]) not in list_of_bad_spectra:\n",
    "        \n",
    "            \n",
    "            df_info.loc[idx] = [int(value[\"number\"]),value[\"object\"],value[\"dateobs\"],value[\"refhour\"],value[\"airmass\"],value[\"pressure\"],value[\"temperature\"],value[\"humidity\"],key,value['targetx_pix'],value['targety_pix'],value['rotangle'], value['d2ccd']] \n",
    "        \n",
    "            df = pd.DataFrame()\n",
    "            df[\"all_lambdas\"] = value[\"all_lambdas\"]\n",
    "            df[\"all_fluxes\"] = value[\"all_fluxes\"]/correction_area*factor\n",
    "            df[\"all_fluxes_err\"] = value[\"all_fluxes_err\"]*factor\n",
    "        \n",
    "            if 'all_lambdas_order2' in value.keys():\n",
    "                df[\"all_lambdas_order2\"] = value[\"all_lambdas_order2\"]\n",
    "                df[\"all_fluxes_order2\"] = value[\"all_fluxes_order2\"]/correction_area*factor\n",
    "                df[\"all_fluxes_err_order2\"] = value[\"all_fluxes_err_order2\"]*factor\n",
    "               \n",
    "            all_df.append(df)\n",
    "            idx_out+=1  # increase count on saved spectra\n",
    "            \n",
    "        else:\n",
    "            num = int(value[\"number\"])\n",
    "            msg = f\"Remove spectrum {idx} for exposure {num}\"\n",
    "            print(msg)\n",
    "            \n",
    "        idx+=1\n",
    "            \n",
    "\n",
    "        \n",
    "    return df_info,all_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetSpectraH5Filtered(h5spectra,list_of_bad_spectra,factor=1.):\n",
    "    \"\"\"\n",
    "    GetSpectraH5Filtered(dict_spectra)\n",
    "    \n",
    "    input:\n",
    "      h5spectra h5 file descriptor\n",
    " \n",
    "    return\n",
    "      - list of dataframes\n",
    "    \"\"\"\n",
    "    \n",
    "    # indexes in H5 file\n",
    "    list_of_keys = list(h5spectra.keys())\n",
    "    sorted_spectra_keys = sorted(list_of_keys)\n",
    "    \n",
    "    # compute the list of filtered spectra\n",
    "    sorted_selected_spectra_keys = [] \n",
    "    for key in sorted_spectra_keys:\n",
    "        key_num = int(key)\n",
    "        seq = key_num - (key_num//100000)*100000\n",
    "        if seq not in list_of_bad_spectra and str(seq) not in list_of_bad_spectra:\n",
    "            sorted_selected_spectra_keys.append(key)\n",
    "       \n",
    "    \n",
    "    # pick one key    \n",
    "    key_sel =  sorted_selected_spectra_keys[0]\n",
    "    # pick one group\n",
    "    group = h5spectra.get(key_sel)\n",
    "    \n",
    "    #pickup all attribute names\n",
    "    all_subgroup_keys = []\n",
    "    for k in group.attrs.keys():\n",
    "        all_subgroup_keys.append(k)  \n",
    "        \n",
    "\n",
    "    # create info\n",
    "    df_info = pd.DataFrame()\n",
    "    for key in all_subgroup_keys:\n",
    "        arr=GetColumnHfData(hf, sorted_selected_spectra_keys ,key)\n",
    "        df_info[key] = arr\n",
    "    \n",
    "    df_info = reorder(df_info,all_subgroup_keys)\n",
    "    \n",
    "    \n",
    "    #correction_area = 1.06/1.13\n",
    "    correction_area = 1\n",
    "\n",
    "    all_df = []  # container for spectra\n",
    "    \n",
    "    #d = h5group.create_dataset(\"spec_lambdas\",data=spec.lambdas,compression=\"gzip\", compression_opts=9)\n",
    "    #d = h5group.create_dataset(\"spec_data\",data=spec.data,compression=\"gzip\", compression_opts=9)\n",
    "    #d = h5group.create_dataset(\"spec_err\",data=spec.err,compression=\"gzip\", compression_opts=9)\n",
    "    #d = h5group.create_dataset(\"spec_covmatrix\",data=spec.cov_matrix,compression=\"gzip\", compression_opts=9)\n",
    "    #d = h5group.create_dataset(\"spec_data_next_order\",data=spec.data_next_order,compression=\"gzip\", compression_opts=9)\n",
    "    #d = h5group.create_dataset(\"spec_err_next_order\",data=spec.err_next_order,compression=\"gzip\", compression_opt\n",
    "    \n",
    "    idx=0\n",
    "    for key in sorted_selected_spectra_keys:\n",
    "        \n",
    "        group = h5spectra.get(key)\n",
    "               \n",
    "        df = pd.DataFrame()\n",
    "        data_next_order=  np.array(group.get(\"spec_data_next_order\"))\n",
    "        \n",
    "        df[\"all_lambdas\"] = np.array(group.get(\"spec_lambdas\"))\n",
    "        df[\"all_fluxes\"] = np.array(group.get(\"spec_data\")) / correction_area*factor \n",
    "        df[\"all_fluxes_err\"] = np.array(group.get(\"spec_err\")) /correction_area*factor\n",
    "        \n",
    "        \n",
    "        df[\"all_lambdas_order2\"] = np.array(group.get(\"spec_lambdas\"))\n",
    "        df[\"all_fluxes_order2\"] = np.array(group.get(\"spec_data_next_order\"))/ correction_area*factor \n",
    "        df[\"all_fluxes_err_order2\"] = np.array(group.get(\"spec_err_next_order\"))/ correction_area*factor \n",
    "        \n",
    "        all_df.append(df)\n",
    "        \n",
    "        idx+=1\n",
    "        \n",
    "    return df_info , all_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FindPairOfExposures(df):\n",
    "    \"\"\"\n",
    "    \n",
    "    Find pair of exposures at similar airmass, one before culmination, the other one after the exposure\n",
    "    \n",
    "    - input : pandas dataframe with infos\n",
    "    - output : pandas dataframe with pairs\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    " \n",
    "    # the culmination  \n",
    "    idx_zmin = df[\"airmass\"].idxmin()\n",
    "    \n",
    "    # split this dataframe into 2\n",
    "    \n",
    "    # df before culmination\n",
    "    df1 = df.iloc[0:idx_zmin]\n",
    "    \n",
    "    # df after culmination\n",
    "    df2 = df.iloc[idx_zmin+1:-1]\n",
    "    \n",
    "    #print(df1)\n",
    "    \n",
    "    #print(df2)\n",
    "    \n",
    "    # loop on exposure before culmination\n",
    "    #for irow in range(0,idx_zmin):\n",
    "        # print(irow,df1.iloc[irow][[\"number\",\"airmass\"]])\n",
    "        \n",
    "    dist = np.abs(df1[\"airmass\"][np.newaxis, :] - df2[\"airmass\"][:, np.newaxis])\n",
    "    #print(dist)\n",
    "    closest_idx = np.argmin(dist, axis=0)\n",
    "    closest_id = df2.iloc[closest_idx][\"number\"].to_numpy()\n",
    "    df_output = pd.DataFrame({\"idx1\": np.arange(0,idx_zmin), \n",
    "                              \"idx2\": closest_idx+idx_zmin+1,\n",
    "                              \"num1\":df1[\"number\"],\n",
    "                              \"num2\":closest_id,\n",
    "                              \"z1\":df1[\"airmass\"].values,\n",
    "                              \"z2\":df2.iloc[closest_idx][\"airmass\"].to_numpy()})\n",
    "\n",
    "    df_output[\"zdiff\"] =  df_output[\"z2\"]-df_output[\"z1\"]\n",
    "    df_output[\"dtime\"] = df2.iloc[closest_idx][\"refhour\"].to_numpy()- df1[\"refhour\"] \n",
    "    return df_output\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FindPairOfExposuresFromFirst(df):\n",
    "    \"\"\"\n",
    "    \n",
    "    - input : pandas dataframe with infos\n",
    "    - output : pandas dataframe with pairs\n",
    "    \n",
    "    \"\"\" \n",
    " \n",
    "\n",
    "    idx_start = 0\n",
    "    \n",
    "    # split this dataframe into 2\n",
    "    \n",
    "    # df before culmination\n",
    "    df1 = df.iloc[:idx_start+1]\n",
    "    \n",
    "    # df after culmination\n",
    "    df2 = df.iloc[idx_start+1:]\n",
    "    N2=len(df2)\n",
    "    \n",
    "\n",
    "    df1_new = df1.copy(deep=True)\n",
    "    df1_new = pd.concat([df1]*(N2),axis=0)\n",
    " \n",
    "    df1=df1_new\n",
    "    N1=len(df1)\n",
    "   \n",
    "    df_output = pd.DataFrame({\"idx1\": np.full(N1,0), \n",
    "                              \"idx2\": np.arange(1,N2+1),\n",
    "                              \"num1\":df1[\"number\"].values,\n",
    "                              \"num2\":df2[\"number\"].values,\n",
    "                              \"z1\":df1[\"airmass\"].values,\n",
    "                              \"z2\":df2[\"airmass\"].values,\n",
    "                              \"t1\":df1[\"refhour\"].values,\n",
    "                              \"t2\":df2[\"refhour\"].values})\n",
    "\n",
    "    df_output[\"zdiff\"] =  df_output[\"z2\"]-df_output[\"z1\"]\n",
    "    df_output[\"dtime\"] = df_output[\"t2\"]-df_output[\"t1\"]\n",
    "    return df1,df2,df_output\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleAtmEmulator:\n",
    "    \"\"\"\n",
    "    Emulate Atmospheric Transparency above LSST from a data grids\n",
    "    extracted from libradtran and analytical functions for aerosols.\n",
    "    There are 3 grids:\n",
    "    - 2D grid Rayleigh transmission vs (wavelength,airmass)\n",
    "    - 2D grid O2 absorption vs  (wavelength,airmass)\n",
    "    - 3D grid for PWV absorption vs (wavelength,airmass,PWV)\n",
    "    - 3D grid for Ozone absorption vs (wavelength,airmass,Ozone)\n",
    "    - Aerosol transmission for any number of components\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self,path='../data/simplegrid'):\n",
    "        \"\"\"\n",
    "        Initialize the class for data point files from which the 2D and 3D grids are created.\n",
    "        Interpolation are calculated from the scipy RegularGridInterpolator() function\n",
    "        \n",
    "        \"\"\"\n",
    "        self.path = path\n",
    "        self.fn_info_training = \"atmospherictransparencygrid_params_training.pickle\"\n",
    "        self.fn_info_test = \"atmospherictransparencygrid_params_test.pickle\"\n",
    "        self.fn_rayleigh_training = \"atmospherictransparencygrid_rayleigh_training.npy\"\n",
    "        self.fn_rayleigh_test = \"atmospherictransparencygrid_rayleigh_test.npy\"\n",
    "        self.fn_O2abs_training = \"atmospherictransparencygrid_O2abs_training.npy\"\n",
    "        self.fn_O2abs_test = \"atmospherictransparencygrid_O2abs_test.npy\"\n",
    "        self.fn_PWVabs_training = \"atmospherictransparencygrid_PWVabs_training.npy\"\n",
    "        self.fn_PWVabs_test = \"atmospherictransparencygrid_PWVabs_test.npy\"\n",
    "        self.fn_OZabs_training = \"atmospherictransparencygrid_OZabs_training.npy\"\n",
    "        self.fn_OZabs_test = \"atmospherictransparencygrid_OZabs_test.npy\"\n",
    "\n",
    "        self.info_params_training = None\n",
    "        self.info_params_test = None\n",
    "        self.data_rayleigh_training = None\n",
    "        self.data_rayleigh_test = None\n",
    "        self.data_O2abs_training = None\n",
    "        self.data_O2abs_test = None\n",
    "        self.data_PWVabs_training = None\n",
    "        self.data_PWVabs_test = None\n",
    "        self.data_OZabs_training = None\n",
    "        self.data_OZabs_test = None\n",
    "        \n",
    "        self.loadtables()\n",
    "        \n",
    "        self.WLMIN = self.info_params_training[\"WLMIN\"]\n",
    "        self.WLMAX = self.info_params_training[\"WLMAX\"]\n",
    "        self.WLBIN = self.info_params_training[\"WLBIN\"]\n",
    "        self.NWLBIN = self.info_params_training['NWLBIN']\n",
    "        self.WL = self.info_params_training['WL']\n",
    "        \n",
    "        self.AIRMASSMIN = self.info_params_training['AIRMASSMIN']\n",
    "        self.AIRMASSMAX = self.info_params_training['AIRMASSMAX']\n",
    "        self.NAIRMASS = self.info_params_training['NAIRMASS']\n",
    "        self.DAIRMASS = self.info_params_training['DAIRMASS']\n",
    "        self.AIRMASS = self.info_params_training['AIRMASS']\n",
    "        \n",
    "        self.PWVMIN = self.info_params_training['PWVMIN']\n",
    "        self.PWVMAX = self.info_params_training['PWVMAX'] \n",
    "        self.NPWV = self.info_params_training['NPWV']\n",
    "        self.DPWV = self.info_params_training['DPWV'] \n",
    "        self.PWV = self.info_params_training['PWV']\n",
    "        \n",
    "        \n",
    "        self.OZMIN =  self.info_params_training['OZMIN']\n",
    "        self.OZMAX = self.info_params_training['OZMAX']\n",
    "        self.NOZ = self.info_params_training['NOZ']\n",
    "        self.DOZ =  self.info_params_training['DOZ'] \n",
    "        self.OZ = self.info_params_training['OZ']\n",
    "        \n",
    "        \n",
    "        self.lambda0 = 550.\n",
    "        self.tau0 = 1.\n",
    "\n",
    "\n",
    "        self.func_rayleigh_train = RegularGridInterpolator((self.WL,self.AIRMASS),self.data_rayleigh_training)\n",
    "        self.func_O2abs_train = RegularGridInterpolator((self.WL,self.AIRMASS),self.data_O2abs_training)\n",
    "        self.func_PWVabs_train = RegularGridInterpolator((self.WL,self.AIRMASS,self.PWV),self.data_PWVabs_training)\n",
    "        self.func_OZabs_train = RegularGridInterpolator((self.WL,self.AIRMASS,self.OZ),self.data_OZabs_training)\n",
    "\n",
    "        \n",
    "        \n",
    "    def loadtables(self):\n",
    "        \"\"\"\n",
    "        Load files into grid arrays\n",
    "        \"\"\"\n",
    "        \n",
    "        filename=os.path.join(self.path,self.fn_info_training)     \n",
    "        with open(filename, 'rb') as f:\n",
    "            self.info_params_training = pickle.load(f)\n",
    "            \n",
    "        filename=os.path.join(self.path,self.fn_info_test)     \n",
    "        with open(filename, 'rb') as f:\n",
    "            self.info_params_test = pickle.load(f)        \n",
    "        \n",
    "        filename=os.path.join(self.path,self.fn_rayleigh_training)\n",
    "        with open(filename, 'rb') as f:\n",
    "            self.data_rayleigh_training=np.load(f)\n",
    "            \n",
    "        filename=os.path.join(self.path,self.fn_rayleigh_test)\n",
    "        with open(filename, 'rb') as f:\n",
    "            self.data_rayleigh_test=np.load(f)\n",
    "            \n",
    "        filename=os.path.join(self.path,self.fn_O2abs_training)\n",
    "        with open(filename, 'rb') as f:\n",
    "            self.data_O2abs_training=np.load(f)\n",
    "            \n",
    "        filename=os.path.join(self.path,self.fn_O2abs_test)\n",
    "        with open(filename, 'rb') as f:\n",
    "            self.data_O2abs_test=np.load(f)\n",
    "                  \n",
    "        filename=os.path.join(self.path,self.fn_PWVabs_training)\n",
    "        with open(filename, 'rb') as f:\n",
    "            self.data_PWVabs_training=np.load(f)\n",
    "            \n",
    "        filename=os.path.join(self.path,self.fn_PWVabs_test)\n",
    "        with open(filename, 'rb') as f:\n",
    "            self.data_PWVabs_test=np.load(f)\n",
    "            \n",
    "            \n",
    "        filename=os.path.join(self.path,self.fn_OZabs_training)\n",
    "        with open(filename, 'rb') as f:\n",
    "            self.data_OZabs_training=np.load(f)\n",
    "            \n",
    "        filename=os.path.join(self.path,self.fn_OZabs_test)\n",
    "        with open(filename, 'rb') as f:\n",
    "            self.data_OZabs_test=np.load(f)\n",
    "\n",
    "    def GetWL(self):\n",
    "        return self.WL\n",
    "            \n",
    "    def GetRayleighTransparencyArray(self,wl,am):\n",
    "        pts = [ (the_wl,am) for the_wl in wl ]\n",
    "        pts = np.array(pts)\n",
    "        return self.func_rayleigh_train(pts)\n",
    "    \n",
    "    \n",
    "    def GetO2absTransparencyArray(self,wl,am):\n",
    "        pts = [ (the_wl,am) for the_wl in wl ]\n",
    "        pts = np.array(pts)\n",
    "        return self.func_O2abs_train(pts)\n",
    "    \n",
    "    \n",
    "    def GetPWVabsTransparencyArray(self,wl,am,pwv):\n",
    "        pts = [ (the_wl,am,pwv) for the_wl in wl ]\n",
    "        pts = np.array(pts)\n",
    "        return self.func_PWVabs_train(pts)\n",
    "    \n",
    "    \n",
    "    def GetOZabsTransparencyArray(self,wl,am,oz):\n",
    "        pts = [ (the_wl,am,oz) for the_wl in wl ]\n",
    "        pts = np.array(pts)\n",
    "        return self.func_OZabs_train(pts)\n",
    "            \n",
    "\n",
    "    \n",
    "    def GetGriddedTransparencies(self,wl,am,pwv,oz,flagRayleigh=True,flagO2abs=True,flagPWVabs=True,flagOZabs=True):\n",
    "        \"\"\"\n",
    "        Emulation of libradtran simulated transparencies. Decomposition of the\n",
    "        total transmission in different processes:\n",
    "        - Rayleigh scattering\n",
    "        - O2 absorption\n",
    "        - PWV absorption\n",
    "        - Ozone absorption\n",
    "        \n",
    "        inputs:\n",
    "        - wl : wavelength array or list\n",
    "        - am :the airmass,\n",
    "        - pwv : the precipitable water vapor (mm)\n",
    "        - oz : the ozone column depth in Dobson unit\n",
    "        - flags to activate or not the individual interaction processes\n",
    "        \n",
    "        outputs:\n",
    "        - 1D array of atmospheric transmission (save size as wl)\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "\n",
    "\n",
    "        if flagRayleigh:\n",
    "            transm = self.GetRayleighTransparencyArray(wl,am)\n",
    "        else:\n",
    "            transm = np.ones(len(wl))\n",
    "            \n",
    "        if flagO2abs:\n",
    "            transm *= self.GetO2absTransparencyArray(wl,am)\n",
    "            \n",
    "        if flagPWVabs:\n",
    "            transm *= self.GetPWVabsTransparencyArray(wl,am,pwv)\n",
    "            \n",
    "        if flagOZabs:\n",
    "            transm *= self.GetOZabsTransparencyArray(wl,am,oz)\n",
    "            \n",
    "        return transm\n",
    "            \n",
    "    def GetAerosolsTransparencies(self,wl,am,ncomp,taus=None,betas=None):\n",
    "        \"\"\"\n",
    "        Compute transmission due to aerosols:\n",
    "        \n",
    "        inputs:\n",
    "        - wl : wavelength array\n",
    "        - am : the airmass\n",
    "        - ncomp : the number of aerosol components\n",
    "        - taus : the vertical aerosol depth of each component at lambda0 vavelength\n",
    "        - betas : the angstrom exponent. Must be negativ.\n",
    "        \n",
    "        \n",
    "        outputs:\n",
    "        - 1D array of atmospheric transmission (save size as wl)\n",
    "        \n",
    "        \"\"\"\n",
    "          \n",
    "        wl = np.array(wl)\n",
    "        NWL=wl.shape[0]\n",
    "        \n",
    "        transm = np.ones(NWL)\n",
    "        \n",
    "        if ncomp <=0:\n",
    "            return transm\n",
    "        else:\n",
    "            taus=np.array(taus)\n",
    "            betas=np.array(betas)\n",
    "            \n",
    "            NTAUS=taus.shape[0]\n",
    "            NBETAS=betas.shape[0]\n",
    "        \n",
    "            assert ncomp<=NTAUS\n",
    "            assert ncomp<=NBETAS     \n",
    "        \n",
    "            for icomp in range(ncomp):            \n",
    "                exponent = (taus[icomp]/self.tau0)*np.exp(betas[icomp]*np.log(wl/self.lambda0))*am\n",
    "                transm *= np.exp(-exponent)\n",
    "            \n",
    "            return transm\n",
    "        \n",
    "        \n",
    "    def GetAllTransparencies(self,wl,am,pwv,oz,ncomp=0, taus=None, betas=None, flagRayleigh=True,flagO2abs=True,flagPWVabs=True,flagOZabs=True,flagAerosols=False):\n",
    "        \"\"\"\n",
    "        Combine interpolated libradtran transmission with analytical expression for the\n",
    "        aerosols\n",
    "        \n",
    "        inputs:\n",
    "        - wl : wavelength array or list\n",
    "        - am :the airmass,\n",
    "        - pwv : the precipitable water vapor (mm)\n",
    "        - oz : the ozone column depth in Dobson unit\n",
    "        - ncomp : number of aerosols components,\n",
    "        - taus & betas : arrays of parameters for aerosols\n",
    "        - flags to activate or not the individual interaction processes\n",
    "        \n",
    "        outputs:\n",
    "        - 1D array of atmospheric transmission (save size as wl)\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "        transm = self.GetGriddedTransparencies(wl,am,pwv,oz,flagRayleigh=flagRayleigh,flagO2abs=flagO2abs,flagPWVabs=flagPWVabs,flagOZabs=flagOZabs)\n",
    "        \n",
    "        if flagAerosols:\n",
    "            transmaer = self.GetAerosolsTransparencies(wl,am,ncomp,taus,betas)\n",
    "            transm *=transmaer\n",
    "           \n",
    "            \n",
    "        return transm\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi2_fit_max = 25\n",
    "chi2_fit_min = 0\n",
    "\n",
    "d2ccd_max = 189\n",
    "d2ccd_min = 186.6\n",
    "\n",
    "pixshift_max = 0.3\n",
    "pixshift_min = -0.3\n",
    "\n",
    "xtarget_min = 50\n",
    "xtarget_max = 250\n",
    "\n",
    "ytarget_min = 700\n",
    "ytarget_max = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SelectionCriteria(row):\n",
    "    \"\"\"\n",
    "    Calculate the Spectrum selection flag on pandas dataframe\n",
    "    call it on a dataframe df as   \n",
    "    flag_selection = df[[\"spec_header_d2ccd\",\"spec_header_targetx\",\"spec_header_targety\"]].apply(SelectionCriteria,axis=1)\n",
    "    \"\"\"\n",
    "    d2ccd = row[\"spec_header_d2ccd\"]\n",
    "    xtarget = row[\"spec_header_targetx\"]\n",
    "    ytarget = row[\"spec_header_targety\"]\n",
    "    \n",
    "    flag_selection_d2ccd = (d2ccd > d2ccd_min)  and (d2ccd < d2ccd_max) \n",
    "    flag_selection_target = (xtarget > xtarget_min)  and (xtarget < xtarget_max ) and (ytarget > ytarget_min)  and (ytarget < ytarget_max )\n",
    "    flag_selection = flag_selection_d2ccd and flag_selection_target\n",
    "    return flag_selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start with logs\n",
    "#-----------------\n",
    "logging.basicConfig()\n",
    "logging.root.setLevel(logging.NOTSET)\n",
    "\n",
    "handle = __name__\n",
    "\n",
    "logger = logging.getLogger(handle)\n",
    "# logging.getLogger().setLevel(logging.INFO)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "# If you don't want to see log messages from libraries, you can pass a\n",
    "# specific logger object to the install() function. In this case only log\n",
    "# messages originating from that logger will show up on the terminal.\n",
    "coloredlogs.install(level='DEBUG', logger=logger)\n",
    "coloredlogs.install(fmt='%(asctime)s,%(msecs)03d %(hostname)s %(name)s[%(process)d] %(levelname)s %(message)s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set time\n",
    "# date\n",
    "today = date.today()\n",
    "string_date = today.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# time\n",
    "now = datetime.now()\n",
    "current_time = now.strftime(\"%H:%M:%S\")\n",
    "\n",
    "tim = time.localtime()\n",
    "current_time = time.strftime(\"%H:%M:%S\", tim)\n",
    "\n",
    "# timezones\n",
    "tz_LA = pytz.timezone('America/Los_Angeles')\n",
    "datetime_LA = datetime.now(tz_LA)\n",
    "msg=\"LA time:\"+  datetime_LA.strftime(\"%H:%M:%S\")\n",
    "logger.info(msg)\n",
    "\n",
    "tz_NY = pytz.timezone('America/New_York')\n",
    "datetime_NY = datetime.now(tz_NY)\n",
    "msg=\"NY time:\"+ datetime_NY.strftime(\"%H:%M:%S\")\n",
    "logger.info(msg)\n",
    "\n",
    "tz_London = pytz.timezone('Europe/London')\n",
    "datetime_London = datetime.now(tz_London)\n",
    "msg=\"London time:\"+ datetime_London.strftime(\"%H:%M:%S\")\n",
    "logger.info(msg)\n",
    "\n",
    "tz_Paris = pytz.timezone('Europe/Paris')\n",
    "datetime_Paris = datetime.now(tz_Paris)\n",
    "msg=\"Paris time:\"+ datetime_Paris.strftime(\"%H:%M:%S\")\n",
    "logger.info(msg)\n",
    "\n",
    "msg=\"************************ START *********************\"\n",
    "logger.info(msg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arguments\n",
    "#----------\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--config\",action=\"store\", dest=\"configfile\",help=f\" run generate -config configfilename, with by ex configfilename = default.ini\")\n",
    "#results_args = parser.parse_args()\n",
    "\n",
    "results_args=\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATE = 20230315\n",
    "FILTERTYPE = \"empty~holo4_003\"\n",
    "spectractormode = \"psf2dffm\"\n",
    "ext = \"rebin2\"   # run BPS by removing ACQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config file\n",
    "# --------------\n",
    "#configfile = \"config/default.ini\"\n",
    "if ext == None or ext == \"\":\n",
    "    configfile = f\"config/{DATE}/{FILTERTYPE}/confprog_run-auxtel-{DATE}-{FILTERTYPE}_{spectractormode}.ini\"\n",
    "else:\n",
    "    configfile = f\"config/{DATE}/{FILTERTYPE}/confprog_run-auxtel-{DATE}-{FILTERTYPE}_{spectractormode}_{ext}.ini\"\n",
    "    \n",
    "#config_filename = results_args.configfile\n",
    "config_filename = configfile\n",
    "msg = f\"Configuration file : {config_filename}\"\n",
    "logger.info(msg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) CONFIGURATION\n",
    "#------------------\n",
    "logger.info('1) Configuration')\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "\n",
    "if os.path.exists(config_filename):\n",
    "    config.read(config_filename)\n",
    "else:\n",
    "    msg = f\"config file {config_filename} does not exist !\"\n",
    "    logger.error(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_section = config.sections()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(config_section) == 0:\n",
    "    msg = f\"empty config file {config_filename} !\"\n",
    "    logger.error(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'GENERAL' in config_section:\n",
    "\n",
    "    FLAG_DEBUG = bool(int(config['GENERAL']['FLAG_DEBUG']))\n",
    "    FLAG_VERBOSE = bool(int(config['GENERAL']['FLAG_VERBOSE']))\n",
    "    FLAG_PLOT   = bool(int(config['GENERAL']['FLAG_PLOT']))\n",
    "    FLAG_PRINT  = bool(int(config['GENERAL']['FLAG_PRINT']))\n",
    "    \n",
    "    SITE          = config['GENERAL']['SITE']\n",
    "    DATE          = config['GENERAL']['DATE']\n",
    "    \n",
    "    inputdir    = config['GENERAL']['inputdir']\n",
    "    inputfile   = config['GENERAL']['inputfile']\n",
    "    filterdisperser =  config['GENERAL']['filterdisperser']\n",
    "    \n",
    "    \n",
    "    \n",
    "    filename_auxtelthroughput = config['GENERAL']['filename_auxtelthroughput']\n",
    "   \n",
    "    spectractormode = config['GENERAL']['spectractormode']\n",
    "   \n",
    "    normalisationfactor = float(config['GENERAL']['normalisationfactor'])\n",
    "    \n",
    "    WLMINSEL      = float(config['GENERAL']['WLMINSEL'])\n",
    "    WLMAXSEL      = float(config['GENERAL']['WLMAXSEL'])\n",
    "    \n",
    "    \n",
    "    MAGLIMMIN     = float(config['GENERAL']['MAGLIMMIN'])\n",
    "    MAGLIMMAX     = float(config['GENERAL']['MAGLIMMAX'])\n",
    "    FLUXLIMMIN    = float(config['GENERAL']['FLUXLIMMIN'])\n",
    "    FLUXLIMMAX    = float(config['GENERAL']['FLUXLIMMAX'])    \n",
    "    \n",
    "    NPOINTSVIEW       =    int(config['GENERAL']['NPOINTSVIEW']) \n",
    "    NPOINTSSAVE       =    int(config['GENERAL']['NPOINTSSAVE']) \n",
    "    inputfile_linearfit =  config['GENERAL']['outputfile_linearfit']\n",
    "    inputfile_gp        =  config['GENERAL']['outputfile_gp']\n",
    "    \n",
    "    BADEXPOS = config['GENERAL']['BADEXPOS']\n",
    "    \n",
    "\n",
    "else:\n",
    "    msg = f\"Configuration file : empty section GENERAL in config file {config_filename} !\"   \n",
    "    logger.error(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file_split=inputfile.split(\".\")    \n",
    "basefilename=input_file_split[0]\n",
    "extendfilename=input_file_split[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_badnums1 = [int(nn)  for nn in BADEXPOS.split()]\n",
    "list_of_badnums1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WL= np.arange(WLMINSEL,WLMAXSEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# input files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Calspec SED"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Notice we use a relative normalisation factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_calspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_f_sed = {}\n",
    "dict_name_sed = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for targetid, sedfilename in dict_sedfilename.items():\n",
    "    print(targetid, '->', sedfilename)\n",
    "    s0=S.FileSpectrum(os.path.join(path_calspec,sedfilename))\n",
    "    \n",
    "    the_targetname = s0.fheader['TARGETID']\n",
    "    \n",
    "    sed_w=s0.wave/10\n",
    "    sed_f=s0.flux*10*normalisationfactor\n",
    "    sed_idx=np.where(np.logical_and(sed_w> WLMINSEL ,sed_w< WLMAXSEL))[0]\n",
    "    sed_w=sed_w[sed_idx]\n",
    "    sed_f=sed_f[sed_idx]\n",
    "    \n",
    "    # interpolation function\n",
    "    f_sed = interpolate.interp1d(sed_w,sed_f,bounds_error=False,fill_value=\"extrapolate\")\n",
    "    \n",
    "    dict_name_sed[targetid] = the_targetname\n",
    "    dict_f_sed[targetid] = f_sed \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_name_sed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sed_m=-2.5*np.log10(sed_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(8,4))\n",
    "ax=fig.add_subplot(1,1,1)\n",
    "\n",
    "for targetid, f_sed  in dict_f_sed.items():\n",
    "\n",
    "    sed = f_sed(WL)\n",
    "    sed_m=-2.5*np.log10(sed)\n",
    "    \n",
    "    label= f\"{targetid}\"\n",
    "    ax.plot(WL,sed,label=label)\n",
    "    \n",
    "ax.set_xlabel(\"$\\\\lambda (nm)$\")\n",
    "ax.set_ylabel(\"flux $(erg/cm^2/s/nm)$\")\n",
    "ax.set_title(\"CALSPEC SED\")\n",
    "ax.set_yscale('log')\n",
    "ax.legend(loc='upper right')\n",
    "#ax2=ax.twinx()\n",
    "#ax2.plot(sed_w,sed_m,'r-')\n",
    "#ax2.set_ylabel(\"mag\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Throughputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auxtel throughput and  telescope throughput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = np.loadtxt(filename_auxtelthroughput)\n",
    "dft = pd.DataFrame(data=array,columns=[\"lambda\",\"throughput\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dft = pd.read_excel(filename_auxtelthroughput,header=1,index_col=0)\n",
    "dft.reset_index(inplace=True)\n",
    "dft['index'] = dft.reset_index().index\n",
    "dft.set_index('index')\n",
    "dft.rename(columns={'lambda':'lambdas'},inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(6,4))\n",
    "ax=fig.add_subplot(111)\n",
    "ax.plot(dft.lambdas,dft.throughput,\"b-\")\n",
    "ax.set_xlabel(\"$\\\\lambda$ (nm)\")\n",
    "ax.set_ylabel(\"throughput\")\n",
    "ax.set_title(\"auxtel throughput\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interpolation function\n",
    "f_thr = interpolate.interp1d(dft.lambdas,dft.throughput,bounds_error=False,fill_value=\"extrapolate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## spectrum data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullfilename=os.path.join(inputdir,inputfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open(fullfilename, 'rb') as f:\n",
    "#    summary_content = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf =  h5py.File(fullfilename, 'r') \n",
    "list_of_keys = list(hf.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NBSPECTRA=len(summary_content)\n",
    "NBSPECTRA=len(list_of_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg=f\" Number of selected files is {NBSPECTRA}\"\n",
    "logger.info(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wavelength bin colors\n",
    "jet = plt.get_cmap('jet')\n",
    "cNorm = colors.Normalize(vmin=0, vmax=NBSPECTRA)\n",
    "scalarMap = cmx.ScalarMappable(norm=cNorm, cmap=jet)\n",
    "all_colors = scalarMap.to_rgba(np.arange(NBSPECTRA), alpha=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read all files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalisationfactor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#infos, all_spectra = GetSpectra(summary_content,factor = normalisationfactor)\n",
    "infos, all_spectra = GetSpectraH5(hf,factor = normalisationfactor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_seq(row):\n",
    "    return row - (row//100000)*100000\n",
    "infos[\"number\"] = infos[['exposure']].apply(lambda x: get_seq(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N=len(infos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NX=4\n",
    "NY=N/NX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if NY != int(NY):\n",
    "    NY= int(NY)+1\n",
    "else:\n",
    "    NY=int(NY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,NY*3))\n",
    "\n",
    "ny=0\n",
    "nx=0\n",
    "\n",
    "for idx in range(N):\n",
    "    iy = idx//NX\n",
    "    ix = (idx-iy*NX)\n",
    "    \n",
    "    ax=fig.add_subplot(NY,NX,idx+1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    the_df=all_spectra[idx]\n",
    "    \n",
    "    airmassvalue = infos.iloc[idx][\"spec_header_airmass\"]\n",
    "    num = infos.iloc[idx][\"number\"]\n",
    "    label_airmass = f\" z = {airmassvalue:.2f} ({num})\"\n",
    "    the_target = infos.iloc[idx][\"spec_target_label\"]\n",
    "    \n",
    "    #ax.plot(the_df.wavelength,the_df.flux,color=all_colors[ifile])\n",
    "    if num in list_of_badnums1:\n",
    "        thecolor=\"r\"\n",
    "    else:\n",
    "        thecolor=\"b\"\n",
    "    \n",
    "    ax.errorbar(the_df[\"all_lambdas\"],the_df['all_fluxes'],yerr=the_df[\"all_fluxes_err\"], fmt = '-', color=thecolor,capsize = 0.01, ecolor=\"k\", elinewidth = .01,label=the_target)\n",
    "    ax.set_title(label_airmass)\n",
    "    \n",
    "    ax.axvline(HBETA.wavelength,linestyle=\"-\",color=\"k\")\n",
    "    ax.axvline(HALPHA.wavelength,linestyle=\"-\",color=\"k\")\n",
    "    \n",
    "    # O2 line\n",
    "    ax.axvline(O2_1.wavelength,linestyle=\"--\",color=\"k\")\n",
    "    #ax.annotate(O2_1.label, xy=(O2_1.wavelength-5, FLUXLIMMAX/2), color='blue',fontsize=20,fontweight='bold')\n",
    "\n",
    "    ax.axvline(O2_2.wavelength,linestyle=\"--\",color=\"k\")\n",
    "    #ax.annotate(O2_2.label, xy=(O2_2.wavelength, ypos), color='blue',fontsize=20,fontweight='bold')\n",
    "    \n",
    "    ax.legend()\n",
    "    \n",
    "the_title = f\"All spectra {DATE}-{filterdisperser}\"\n",
    "\n",
    "plt.suptitle(the_title,size=20,fontweight='bold',y=0.99)    \n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(top=0.85)\n",
    "\n",
    "fig_filename = f\"fig_01-{DATE}-{filterdisperser}-allspectra.pdf\"\n",
    "plt.savefig(fig_filename)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove bad Spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,4))\n",
    "ax=fig.add_subplot(1,1,1)\n",
    "ax.hist(infos.spec_target_label);\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha='center')\n",
    "ax.set_title(\"nb of spectra per target before spectra selection \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,4))\n",
    "ax=fig.add_subplot(1,3,1)\n",
    "ax.hist(infos.spec_header_d2ccd,bins=20,range=(170,200));\n",
    "ax.set_xlabel(\"spec_header_dccd\")\n",
    "ax=fig.add_subplot(1,3,2)\n",
    "ax.hist(infos.spec_header_targetx,bins=50,range=(0,500));\n",
    "ax.set_xlabel(\"spec_header_targetx\")\n",
    "ax=fig.add_subplot(1,3,3)\n",
    "ax.hist(infos.spec_header_targety,bins=50,range=(0,2000));\n",
    "ax.set_xlabel(\"spec_header_targety\")\n",
    "plt.suptitle(\"Variables to apply selection\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define selection cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selection_cut = ((infos.d2ccd > 178) & (infos.d2ccd < 182)) & (infos.object == target)\n",
    "selection_cut = ((infos.spec_header_d2ccd > 178) & (infos.spec_header_d2ccd < 182))\n",
    "bad_cut = ~selection_cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_badnums2 = infos[bad_cut][\"number\"].values\n",
    "list_of_badnums2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_badnums2  = np.array([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### No SED for HD42525 or HD73495"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selection_cut3 = infos.spec_target_label == \"HD42525\"\n",
    "#AA = infos[\"spec_target_label\"] == \"HD115169\"\n",
    "#AB = infos[\"spec_target_label\"] == \"HD142331\"\n",
    "AC = infos[\"spec_target_label\"] == \"HD146233\"\n",
    "AD = infos[\"spec_target_label\"] == \"HD42525\"\n",
    "AE = infos[\"spec_target_label\"] == \"HD73495\"\n",
    "#AF = infos[\"spec_target_label\"] == \"HD167060\"\n",
    "selection_cut3 =  AC | AD | AE \n",
    "list_of_badnum3 = infos[selection_cut3][\"number\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_badnum3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Union of badnums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_badnums = np.union1d(list_of_badnums1,list_of_badnums2)\n",
    "list_of_badnums = np.union1d(list_of_badnums,list_of_badnum3)\n",
    "list_of_badnums=np.unique(list_of_badnums)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtered spectra : remove bad spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_badnums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#infos, all_spectra = GetSpectraFiltered(summary_content,list_of_bad_spectra=list_of_badnums,factor = normalisationfactor)\n",
    "infos, all_spectra = GetSpectraH5Filtered(hf,list_of_bad_spectra = list_of_badnums , factor = normalisationfactor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infos[\"number\"] = infos[['exposure']].apply(lambda x: get_seq(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of spectra : \",len(all_spectra))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infos.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,4))\n",
    "ax=fig.add_subplot(1,1,1)\n",
    "ax.hist(infos.spec_target_label);\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha='center')\n",
    "ax.set_title(\"nb of spectra per target after spectra selection \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_datetime = [ Time(str_time).to_datetime() for str_time in infos['spec_date_obs'] ]\n",
    "numbers = infos['number'].values\n",
    "airmasses = infos['spec_header_airmass'].values\n",
    "N= len(numbers)\n",
    "\n",
    "myFmt = mdates.DateFormatter('%H:%M')\n",
    "ax.xaxis.set_major_formatter(myFmt)\n",
    "\n",
    "\n",
    "# Create rectangle x coordinates\n",
    "startTime = all_datetime[0]\n",
    "endTime =  datetime(2023, 1, 31, 0, 0, 0, 0),\n",
    "\n",
    "# convert to matplotlib date representation\n",
    "start = mdates.date2num(startTime)\n",
    "end = mdates.date2num(endTime)\n",
    "width = end - start\n",
    "\n",
    "\n",
    "\n",
    "fig=plt.figure(figsize=(20,5))\n",
    "ax=fig.add_subplot(111)\n",
    "#ax.plot(all_datetime,grey_attenuation,'bo:')\n",
    "#ax.grid()\n",
    "#plt.gcf().autofmt_xdate()\n",
    "#ax.xaxis.set_major_formatter(myFmt)\n",
    "#ax.xaxis.set_tick_params(rotation=45)\n",
    "#ax.set_xlabel(\"time (UTC)\")\n",
    "#ax.set_title(f\"Grey attenuation : {DATE} ({filterdisperser}, {target})\")\n",
    "#ax.set_ylabel(\"attenuation\")\n",
    "#ax2 = ax.twinx()\n",
    "\n",
    "y_shift= 0.08\n",
    "\n",
    "ax2=ax\n",
    "ax2.plot(all_datetime,airmasses,'r:o')\n",
    "ax2.xaxis.set_major_formatter(myFmt)\n",
    "ax2.xaxis.set_tick_params(rotation=45)\n",
    "ax2.set_xlabel(\"time (UTC)\")\n",
    "ax2.set_ylabel(\"airmass\")\n",
    "ax2.set_ylim(airmasses.min()-2*y_shift,airmasses.max()+2*y_shift)\n",
    "# Plot rectangle\n",
    "#rect = plt.Rectangle((start, airmasses.min()-2*y_shift), width, airmasses.max()+ 2*y_shift, color='grey',alpha=0.3)\n",
    "#ax2.add_patch(rect)   \n",
    "ax2.invert_yaxis()\n",
    "ax2.grid()\n",
    "\n",
    "\n",
    "for index in range(N):\n",
    "    textstr= str(numbers[index])\n",
    "    if index%2 == 0:\n",
    "        dy = y_shift\n",
    "    else:\n",
    "        dy = -y_shift\n",
    "            \n",
    "    ax2.text(all_datetime[index], airmasses[index] + dy , textstr,fontsize=14,fontweight=\"bold\",ha='center',color=\"b\" )\n",
    "    \n",
    "the_title = f\"All spectra airmass {DATE}-{filterdisperser}\"\n",
    "plt.suptitle(the_title,size=20,fontweight='bold',y=0.99)    \n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(top=0.85)\n",
    "\n",
    "fig_filename = f\"fig_02-{DATE}-{filterdisperser}-airmasses.pdf\"\n",
    "plt.savefig(fig_filename)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulate atmospheric transparency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emul = SimpleAtmEmulator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NBINFOS = len(infos)\n",
    "dict_func_atm = {}\n",
    "print(NBINFOS)\n",
    "\n",
    "pwv0 = 3\n",
    "oz0 = 300.\n",
    "ncomp=0\n",
    "\n",
    "for ispec in range(NBINFOS):\n",
    "    the_infos = infos.iloc[ispec]\n",
    "    the_airmass = the_infos[\"spec_header_airmass\"]\n",
    "    the_number = the_infos[\"number\"]\n",
    "    \n",
    "    transm = emul.GetAllTransparencies(WL,the_airmass,pwv0,oz0,ncomp=ncomp,flagAerosols=False)\n",
    "    dict_func_atm[the_number] = interpolate.interp1d(WL,transm,bounds_error=False,fill_value=\"extrapolate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wavelength bin colors\n",
    "jet = plt.get_cmap('jet')\n",
    "cNorm = colors.Normalize(vmin=0, vmax=NBINFOS)\n",
    "scalarMap = cmx.ScalarMappable(norm=cNorm, cmap=jet)\n",
    "all_colors = scalarMap.to_rgba(np.arange(NBINFOS), alpha=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(16,16))\n",
    "ax=fig.add_subplot(111)\n",
    "for isim in np.arange(NBINFOS):\n",
    "    \n",
    "    airmassvalue = infos.iloc[isim][\"spec_header_airmass\"]\n",
    "    the_number = infos.iloc[isim][\"number\"]\n",
    "    label_airmass = f\" z = {airmassvalue:.2f}({the_number})\"\n",
    "\n",
    "    atm = dict_func_atm[the_number](WL)\n",
    "    \n",
    "    ax.plot(WL,atm, color=all_colors[isim],label=label_airmass)\n",
    "\n",
    "ax.grid()\n",
    "ax.set_xlabel(\"$\\lambda$ (nm)\")\n",
    "ax.set_ylabel(\"air transparency\")\n",
    "title=f\"sim. tmospheric transparencies({DATE}) pwv = {pwv0:.2f} mm oz = {oz0:.0f} DU\"\n",
    "ax.set_title(title,fontsize=20,fontweight='bold')\n",
    "\n",
    "ax.set_xlim( WLMINSEL  , WLMAXSEL  )\n",
    "ax.set_ylim(0.,1)\n",
    "#ax.legend(loc=\"lower left\",ncol=5)\n",
    "#ax.legend(bbox_to_anchor=(1.02, 0.5))\n",
    "ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NBSPECTRA=len(all_spectra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert NBSPECTRA == NBINFOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wavelength bin colors\n",
    "jet = plt.get_cmap('jet')\n",
    "cNorm = colors.Normalize(vmin=0, vmax=NBSPECTRA)\n",
    "scalarMap = cmx.ScalarMappable(norm=cNorm, cmap=jet)\n",
    "all_colors = scalarMap.to_rgba(np.arange(NBSPECTRA), alpha=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg=f\" Number of good spectra is {NBSPECTRA}\"\n",
    "logger.info(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load absorption pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/absorption_pattern.csv\")\n",
    "wlpt,o2,o3,h2o,no2 = atmpatt_Dataf_to_np(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotlines(ax,ypos):\n",
    "    \n",
    "    ax.axvline(HDELTA.wavelength,color='orange')\n",
    "    ax.annotate(HDELTA.label, xy=(HDELTA.wavelength, ypos), color='orange',fontsize=20,fontweight='bold')\n",
    "    \n",
    "    ax.axvline(HGAMMA.wavelength,color='orange')\n",
    "    ax.annotate(HGAMMA.label, xy=(HGAMMA.wavelength, ypos), color='orange',fontsize=20,fontweight='bold')\n",
    "    \n",
    "    ax.axvline(HBETA.wavelength,color='orange')\n",
    "    ax.annotate(HBETA.label, xy=(HBETA.wavelength, ypos), color='orange',fontsize=20,fontweight='bold')\n",
    "    \n",
    "    ax.axvline(HALPHA.wavelength,color='orange')\n",
    "    ax.annotate(HALPHA.label, xy=(HALPHA.wavelength, ypos), color='orange',fontsize=20,fontweight='bold')\n",
    "\n",
    "    ax.axvline(O2B.wavelength,color=\"blue\")\n",
    "    ax.annotate(O2B.label, xy=(O2B.wavelength, ypos), color='blue',fontsize=20,fontweight='bold')\n",
    "\n",
    "    ax.axvline(O2_1.wavelength,color=\"blue\")\n",
    "    #ax.annotate(O2_1.label, xy=(O2_1.wavelength-5, FLUXLIMMAX/2), color='blue',fontsize=20,fontweight='bold')\n",
    "\n",
    "    ax.axvline(O2_2.wavelength,color=\"blue\")\n",
    "    ax.annotate(O2_2.label, xy=(O2_2.wavelength, ypos), color='blue',fontsize=20,fontweight='bold')\n",
    "\n",
    "    ax.axvline(H2O_1.wavelength,color=\"blue\")\n",
    "    ax.annotate(H2O_1.label, xy=(H2O_1.wavelength, ypos), color='blue',fontsize=20,fontweight='bold')\n",
    "    \n",
    "    ax.axvline(H2O_2.wavelength,color=\"blue\")\n",
    "    ax.annotate(H2O_2.label, xy=(H2O_2.wavelength, ypos), color='blue',fontsize=20,fontweight='bold')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize=(16,16)\n",
    "\n",
    "NOBS = o2.shape[1]\n",
    "# wavelength bin colors\n",
    "jet = plt.get_cmap('jet')\n",
    "cNorm = colors.Normalize(vmin=0, vmax=NOBS)\n",
    "scalarMap = cmx.ScalarMappable(norm=cNorm, cmap=jet)\n",
    "all_colors = scalarMap.to_rgba(np.arange(NOBS), alpha=1)\n",
    "\n",
    "props = dict(boxstyle='round', facecolor='wheat', alpha=0.5)\n",
    "\n",
    "fig=plt.figure(figsize=figsize)\n",
    "title =f\"Spectra (hologram) {SITE} ({DATE})\"\n",
    "\n",
    "\n",
    "#gs = gridspec.GridSpec(5, 1,height_ratios=[0.5,0.5,0.5,0.5,4] ,figure=fig)\n",
    "gs = gridspec.GridSpec(4, 1,height_ratios=[0.5,0.5,0.5,4] ,figure=fig)\n",
    "\n",
    "#=========================================================== NO2    \n",
    "#ax=fig.add_subplot(gs[0,0])\n",
    "#for index in np.arange(NOBS):   \n",
    "#    ax.plot(wlpt,no2[:,index],'-',color=all_colors[index])\n",
    "#ax.set_ylim(0.8,1)\n",
    "#ax.set_xlim(WLMINSEL,WLMAXSEL)\n",
    "#ax.grid()\n",
    "#textstr = \"NO2 abs lines\"\n",
    "# place a text box in upper left in axes coords\n",
    "#ax.text(0.01, 0.90, textstr, transform=ax.transAxes, fontsize=14,\n",
    "#        verticalalignment='top', bbox=props)\n",
    "#ax.set_title(title,fontsize=20,fontweight='bold')\n",
    "#main_ax = ax\n",
    "\n",
    "\n",
    "\n",
    "#=========================================================== O2    \n",
    "#ax=fig.add_subplot(gs[0,0], sharex=main_ax)\n",
    "ax=fig.add_subplot(gs[0,0])\n",
    "for index in np.arange(NOBS):   \n",
    "    ax.plot(wlpt,o2[:,index],'-',color=all_colors[index])\n",
    "ax.set_ylim(0.8,1)\n",
    "ax.set_xlim(WLMINSEL,WLMAXSEL)\n",
    "ax.grid()\n",
    "textstr = \"O2 abs lines\"\n",
    "# place a text box in upper left in axes coords\n",
    "ax.text(0.01, 0.90, textstr, transform=ax.transAxes, fontsize=14,\n",
    "        verticalalignment='top', bbox=props)\n",
    "#ax.set_title(title)\n",
    "main_ax = ax\n",
    "\n",
    "#=========================================================== Ozone\n",
    "ax=fig.add_subplot(gs[1,0], sharex=main_ax)\n",
    "for index in np.arange(NOBS):   \n",
    "    ax.plot(wlpt,o3[:,index],'-',color=all_colors[index])\n",
    "ax.set_ylim(0.8,1)\n",
    "ax.set_xlim(WLMINSEL,WLMAXSEL)\n",
    "ax.grid()\n",
    "textstr = \"O3 abs lines\"\n",
    "# place a text box in upper left in axes coords\n",
    "ax.text(0.01, 0.90, textstr, transform=ax.transAxes, fontsize=14,\n",
    "        verticalalignment='top', bbox=props)\n",
    "\n",
    "\n",
    "#=========================================================== H2O\n",
    "ax=fig.add_subplot(gs[2,0], sharex=main_ax)\n",
    "\n",
    "for index in np.arange(NOBS):   \n",
    "    ax.plot(wlpt,h2o[:,index],'-',color=all_colors[index])\n",
    "ax.set_ylim(0.8,1)\n",
    "ax.grid()\n",
    "textstr = \"H2O abs lines\"\n",
    "# place a text box in upper left in axes coords\n",
    "ax.text(0.01, 0.90, textstr, transform=ax.transAxes, fontsize=14,\n",
    "        verticalalignment='top', bbox=props)\n",
    "\n",
    "\n",
    "#================================================= spectra\n",
    "ax=fig.add_subplot(gs[3,0], sharex=main_ax)\n",
    "\n",
    "# wavelength bin colors\n",
    "jet = plt.get_cmap('jet')\n",
    "cNorm = colors.Normalize(vmin=0, vmax=NBSPECTRA)\n",
    "scalarMap = cmx.ScalarMappable(norm=cNorm, cmap=jet)\n",
    "all_colors = scalarMap.to_rgba(np.arange(NBSPECTRA), alpha=1)\n",
    "all_numbers = infos['number'].values\n",
    "\n",
    "\n",
    "\n",
    "for ifile in np.arange(NBSPECTRA):\n",
    "    the_df=all_spectra[ifile]\n",
    "    \n",
    "    airmassvalue = infos.iloc[ifile][\"spec_header_airmass\"]\n",
    "    the_number = all_numbers[ifile]\n",
    "    label_airmass = f\" z = {airmassvalue:.2f}({the_number})\"\n",
    "\n",
    "    #ax.plot(the_df.wavelength,the_df.flux,color=all_colors[ifile])\n",
    "    ax.errorbar(the_df[\"all_lambdas\"],the_df['all_fluxes'],yerr=the_df[\"all_fluxes_err\"], fmt = '.', color=all_colors[ifile],capsize = 0.01, ecolor=all_colors[ifile], elinewidth = .01,label=label_airmass)\n",
    "ax.grid()\n",
    "ax.set_xlabel(\"$\\lambda$ (nm)\")\n",
    "ax.set_ylabel(\"flux (erg/sec/m$^2$/nm)\")\n",
    "title=f\"Selected Spectra observed at {SITE} ({DATE})\"\n",
    "ax.set_title(title,fontsize=20,fontweight='bold')\n",
    "#ax.plot(sed_w,sed_f,'k-')\n",
    "#ax.set_xlim(350,1000)\n",
    "#ax.set_ylim(1e-14,1e-10)\n",
    "#ax.set_ylim(FLUXLIMMIN,FLUXLIMMAX)\n",
    "ax.set_yscale(\"log\")\n",
    "ax.legend(loc=\"lower left\",ncol=6)\n",
    "#ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "# draw abs lines\n",
    "plotlines(ax,ypos=FLUXLIMMAX/2)\n",
    "\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(16,16))\n",
    "ax=fig.add_subplot(111)\n",
    "for ifile in np.arange(NBSPECTRA):\n",
    "    the_df=all_spectra[ifile]\n",
    "    \n",
    "    airmassvalue = infos.iloc[ifile][\"spec_header_airmass\"]\n",
    "    the_number = all_numbers[ifile]\n",
    "    label_airmass = f\" z = {airmassvalue:.2f}({the_number})\"\n",
    "\n",
    "    #ax.plot(the_df.wavelength,the_df.flux,color=all_colors[ifile])\n",
    "    ax.errorbar(the_df[\"all_lambdas\"],the_df['all_fluxes'],yerr=the_df[\"all_fluxes_err\"], fmt = '.', color=all_colors[ifile],capsize = 0.01, ecolor=all_colors[ifile], elinewidth = .01,label=label_airmass)\n",
    "\n",
    "    f_flux = interpolate.interp1d(the_df[\"all_lambdas\"].values,the_df['all_fluxes'].values,bounds_error=False,fill_value=0)\n",
    "    x1=1000.\n",
    "    y1=f_flux(x1)\n",
    "    s1=str(the_number)\n",
    "    x2=600\n",
    "    y2=f_flux(x2)\n",
    "    s2=infos.iloc[ifile][\"spec_target_label\"]\n",
    "    ax.text(x1+5, y1, s1, color=all_colors[ifile],fontsize=12)\n",
    "    ax.text(x2+15, y2*1.1, s2, color=all_colors[ifile],fontsize=14)\n",
    "    \n",
    "ax.grid()\n",
    "ax.set_xlabel(\"$\\lambda$ (nm)\")\n",
    "ax.set_ylabel(\"flux (erg/sec/m$^2$/nm)\")\n",
    "title=f\"Selected Spectra observed at {SITE} ({DATE})\"\n",
    "ax.set_title(title,fontsize=20,fontweight='bold')\n",
    "#ax.plot(sed_w,sed_f,'k-')\n",
    "ax.set_xlim( WLMINSEL  , WLMAXSEL  )\n",
    "ax.set_ylim(FLUXLIMMIN,FLUXLIMMAX)\n",
    "ax.set_yscale(\"log\")\n",
    "#ax.legend(loc=\"lower left\",ncol=5)\n",
    "#ax.legend(bbox_to_anchor=(1.02, 0.5))\n",
    "ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "# draw abs lines\n",
    "plotlines(ax,ypos=FLUXLIMMAX/2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correction_area = 1.06/1.13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sed_predicted_f = f_sed(WL) * f_thr(WL) * f_atm(WL) \n",
    "#sed_predicted_m = -2.5*np.log10(sed_predicted_f) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select the identifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_ratio = {}\n",
    "array_ratio = np.zeros((NBSPECTRA,len(WL)))\n",
    "\n",
    "for idx in range(NBSPECTRA):\n",
    "    \n",
    "    fig=plt.figure(figsize=(16,10))\n",
    "    gs = gridspec.GridSpec(2, 1,height_ratios=[4,1] ,figure=fig)\n",
    "\n",
    "\n",
    "    # Fig 1\n",
    "    ax=fig.add_subplot(gs[0,0])\n",
    "\n",
    "    # extract spectrum from data\n",
    "    the_df=all_spectra[idx]\n",
    "    the_number = infos.iloc[idx][\"number\"]\n",
    "    airmassvalue = infos.iloc[idx][\"spec_header_airmass\"]\n",
    "    target = infos.iloc[idx][\"spec_target_label\"]\n",
    "    label_airmass = f\" {target}({the_number}) : z = {airmassvalue:.2f}\"\n",
    "\n",
    "    # the SED\n",
    "    f_sed = dict_f_sed[target] \n",
    "\n",
    "    # atmosphere\n",
    "    the_f_atm = dict_func_atm[the_number]\n",
    "\n",
    "    # the throughput\n",
    "    #f_thr\n",
    "\n",
    "    # prediction\n",
    "    the_wl = the_df[\"all_lambdas\"].values\n",
    "    the_sim = f_sed(the_wl) * the_f_atm(the_wl) * f_thr(the_wl)\n",
    "\n",
    "\n",
    "    ax.errorbar(the_df[\"all_lambdas\"],the_df['all_fluxes']/correction_area,yerr=the_df[\"all_fluxes_err\"], fmt = '.',color=\"b\",capsize = 0.01, ecolor=all_colors[ifile], elinewidth = .01,label=label_airmass)\n",
    "    ax.plot(the_wl,the_sim,'-r')\n",
    "\n",
    "    ax.grid()\n",
    "    ax.set_xlabel(\"$\\lambda$ (nm)\")\n",
    "    ax.set_ylabel(\"flux (erg/sec/m$^2$/nm)\")\n",
    "    title=f\"Obs Spectr from {target} at {SITE} ({DATE})\"\n",
    "    ax.set_title(title,fontsize=20,fontweight='bold')\n",
    "    #ax.plot(sed_w,sed_f,'k-',label=\"SED\")\n",
    "    #ax.plot(WL,sed_predicted_f,color='darkviolet',lw=4,label = \"predicted flux\")\n",
    "    ax.set_xlim( WLMINSEL  , WLMAXSEL  )\n",
    "\n",
    "    ax.legend(loc=\"upper right\")\n",
    "    # draw abs lines\n",
    "    plotlines(ax,ypos=FLUXLIMMAX/30)\n",
    "    \n",
    "    ax.axvline(x=758,linewidth=2,linestyle=\":\" ,color='purple')\n",
    "    ax.axvline(x=767,linewidth=2,linestyle=':', color='purple')\n",
    "    \n",
    "    ax.axvline(x=920,linewidth=2,linestyle=\":\" ,color='purple')\n",
    "    ax.axvline(x=980,linewidth=2,linestyle=':', color='purple')\n",
    "    \n",
    "\n",
    "    main_ax = ax\n",
    "\n",
    "    # Fig 2\n",
    "    ax=fig.add_subplot(gs[1,0], sharex=main_ax)\n",
    "\n",
    "    ax.errorbar(the_wl,the_df['all_fluxes']/correction_area/the_sim,yerr=the_df[\"all_fluxes_err\"], fmt = '.',color=\"g\",capsize = 0.01, ecolor=all_colors[ifile], elinewidth = .01,label=label_airmass)\n",
    "    ratio = the_df['all_fluxes']/correction_area/the_sim\n",
    "    \n",
    "    # remove absorption line\n",
    "    xcut1=758\n",
    "    xcut2=767\n",
    "    xcut3=925\n",
    "    xcut4=970\n",
    "    \n",
    "    index_to_remove=np.where(np.logical_or(np.logical_and(the_wl>xcut1,the_wl<xcut2),np.logical_and(the_wl>xcut3,the_wl<xcut4)))[0]\n",
    "    \n",
    "                             \n",
    "    new_the_wl = the_wl[~np.isin(np.arange(the_wl.size), index_to_remove)]\n",
    "    new_ratio = ratio[~np.isin(np.arange(ratio.size), index_to_remove)]\n",
    "    \n",
    "    f_ratio = interpolate.interp1d(new_the_wl,new_ratio,bounds_error=False,fill_value=\"extrapolate\")\n",
    "    ratio_interp =f_ratio(WL)\n",
    "    \n",
    "                                \n",
    "    ax.plot(WL,ratio_interp,'.',color=\"purple\")\n",
    "\n",
    "    span=30\n",
    "    ratio_filtered = smooth_data_np_convolve(ratio_interp,span)\n",
    "    ax.plot(WL,ratio_filtered,'k-',lw=3)\n",
    "    \n",
    "    \n",
    "    dict_ratio[the_number] = ratio_filtered\n",
    "    array_ratio[idx,:] = ratio_filtered\n",
    "    \n",
    "    ax.axvline(x=758,linewidth=2,linestyle=\":\" ,color='r')\n",
    "    ax.axvline(x=767,linewidth=2,linestyle=':', color='r')\n",
    "    \n",
    "    ax.axvline(x=930,linewidth=2,linestyle=\":\" ,color='r')\n",
    "    ax.axvline(x=970,linewidth=2,linestyle=':', color='r')\n",
    "\n",
    "    ax.grid()\n",
    "    ax.set_ylim(0,2)\n",
    "    ax.set_ylabel(\"ratio data/sim\")\n",
    "    \n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the median ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio_median = np.median(array_ratio,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hls_colors = sns.color_palette(\"hls\", NBSPECTRA)\n",
    "\n",
    "fig=plt.figure(figsize=(16,8))\n",
    "ax=fig.add_subplot(111)\n",
    "\n",
    "idx=0\n",
    "for key, value in dict_ratio.items():\n",
    "    ax.plot(WL,value,\"-\",color=hls_colors[idx],lw=2)\n",
    "    idx+=1\n",
    "    \n",
    "ax.plot(WL,ratio_median,'k-',lw=3)\n",
    "ax.set_xlabel(\"$\\lambda$ (nm)\")  \n",
    "ax.set_ylabel(\"ratio\")\n",
    "ax.set_title(\"ratio data/sim\")\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute the error ratio_median_error  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio_median_error  = np.std(array_ratio-ratio_median,axis=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hls_colors = sns.color_palette(\"hls\", NBSPECTRA)\n",
    "\n",
    "fig=plt.figure(figsize=(16,8))\n",
    "ax=fig.add_subplot(111)\n",
    "\n",
    "idx=0\n",
    "for key, value in dict_ratio.items():\n",
    "    ax.plot(WL,value,\"-\",color=hls_colors[idx],lw=1,alpha=0.5)\n",
    "    idx+=1\n",
    "    \n",
    "ax.errorbar(WL,ratio_median,yerr=ratio_median_error ,fmt='.',color='k',ecolor=\"grey\",lw=1,alpha=1.0)\n",
    "\n",
    "\n",
    "ax.set_ylim(0,1)\n",
    "ax.set_xlabel(\"$\\lambda$ (nm)\")  \n",
    "ax.set_ylabel(\"ratio\")\n",
    "ax.set_title(\"ratio data/sim with error bars\")\n",
    "\n",
    "ax.grid()\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New measured throughput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hls_colors = sns.color_palette(\"hls\",2)\n",
    "\n",
    "new_throughput = f_thr(WL)*ratio_median\n",
    "new_throughput_error = f_thr(WL)*ratio_median_error\n",
    "\n",
    "fig=plt.figure(figsize=(16,8))\n",
    "ax=fig.add_subplot(111)\n",
    "ax.plot(WL,f_thr(WL),'b-',label = \"old Auxtel transmission\",lw=2) \n",
    "ax.plot(WL,new_throughput,'r-',label = \"new Auxtel transmission\",lw=2)\n",
    "ax.errorbar(WL,new_throughput,yerr=new_throughput_error ,fmt='.',color='r',ecolor=\"grey\",lw=1,alpha=1)\n",
    "\n",
    "ax.plot(WL,2*new_throughput,'g-',label = \"new Auxtel transmission x 2\",lw=2)\n",
    "ax.errorbar(WL,2*new_throughput,yerr=new_throughput_error ,fmt='.',color='g',ecolor=\"grey\",lw=1,alpha=1)\n",
    "ax.legend()\n",
    "ax.grid()\n",
    "ax.set_xlabel(\"$\\lambda$ (nm)\")  \n",
    "ax.set_ylabel(\"throughput\")\n",
    "\n",
    "ax.set_title(f\"Auxtel Throughput {DATE} - {filterdisperser} {spectractormode}\")\n",
    "ax.set_ylim(0,.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save new throuthput in a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_th_out = pd.DataFrame()\n",
    "df_th_out[\"wavelength\"] = WL\n",
    "df_th_out[\"newthrou\"] = new_throughput\n",
    "df_th_out[\"newthrouerr\"] = new_throughput_error\n",
    "df_th_out[\"oldthrou\"] = f_thr(WL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_th_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_newthroughput = f\"throughput-{DATE}-{filterdisperser}-{spectractormode}-multifitatmparams.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_th_out.to_csv(filename_newthroughput)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New fittable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_thr_new = interpolate.interp1d(WL,new_throughput,bounds_error=False,fill_value=\"extrapolate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_ratio = {}\n",
    "array_ratio = np.zeros((NBSPECTRA,len(WL)))\n",
    "\n",
    "for idx in range(NBSPECTRA):\n",
    "    \n",
    "    fig=plt.figure(figsize=(16,10))\n",
    "    gs = gridspec.GridSpec(2, 1,height_ratios=[4,1] ,figure=fig)\n",
    "\n",
    "\n",
    "    # Fig 1\n",
    "    ax=fig.add_subplot(gs[0,0])\n",
    "\n",
    "    # extract spectrum from data\n",
    "    the_df=all_spectra[idx]\n",
    "    the_number = infos.iloc[idx][\"number\"]\n",
    "    airmassvalue = infos.iloc[idx][\"spec_header_airmass\"]\n",
    "    target = infos.iloc[idx][\"spec_target_label\"]\n",
    "    label_airmass = f\" {target}({the_number}) : z = {airmassvalue:.2f}\"\n",
    "\n",
    "    # the SED\n",
    "    f_sed = dict_f_sed[target] \n",
    "\n",
    "    # atmosphere\n",
    "    the_f_atm = dict_func_atm[the_number]\n",
    "\n",
    "    # the throughput\n",
    "    #f_thr\n",
    "\n",
    "    # prediction\n",
    "    the_wl = the_df[\"all_lambdas\"].values\n",
    "    the_sim = f_sed(the_wl) * the_f_atm(the_wl) * f_thr_new(the_wl)\n",
    "\n",
    "\n",
    "    ax.errorbar(the_df[\"all_lambdas\"],the_df['all_fluxes']/correction_area,yerr=the_df[\"all_fluxes_err\"], fmt = '.',color=\"b\",capsize = 0.01, ecolor=all_colors[ifile], elinewidth = .01,label=label_airmass)\n",
    "    ax.plot(the_wl,the_sim,'r-',lw=2)\n",
    "\n",
    "    ax.grid()\n",
    "    ax.set_xlabel(\"$\\lambda$ (nm)\")\n",
    "    ax.set_ylabel(\"flux (erg/sec/m$^2$/nm)\")\n",
    "    title=f\"Obs Spectr from {target} at {SITE} ({DATE})\"\n",
    "    ax.set_title(title,fontsize=20,fontweight='bold')\n",
    "    #ax.plot(sed_w,sed_f,'k-',label=\"SED\")\n",
    "    #ax.plot(WL,sed_predicted_f,color='darkviolet',lw=4,label = \"predicted flux\")\n",
    "    ax.set_xlim( WLMINSEL  , WLMAXSEL  )\n",
    "\n",
    "    ax.legend(loc=\"upper right\")\n",
    "    # draw abs lines\n",
    "    plotlines(ax,ypos=FLUXLIMMAX/30)\n",
    "    \n",
    "    ax.axvline(x=758,linewidth=2,linestyle=\":\" ,color='purple')\n",
    "    ax.axvline(x=767,linewidth=2,linestyle=':', color='purple')\n",
    "    \n",
    "    ax.axvline(x=920,linewidth=2,linestyle=\":\" ,color='purple')\n",
    "    ax.axvline(x=980,linewidth=2,linestyle=':', color='purple')\n",
    "    \n",
    "\n",
    "    main_ax = ax\n",
    "\n",
    "    # Fig 2\n",
    "    ax=fig.add_subplot(gs[1,0], sharex=main_ax)\n",
    "\n",
    "    ax.errorbar(the_wl,the_df['all_fluxes']/correction_area/the_sim,yerr=the_df[\"all_fluxes_err\"], fmt = '.',color=\"g\",capsize = 0.01, ecolor=all_colors[ifile], elinewidth = .01,label=label_airmass)\n",
    "    ratio = the_df['all_fluxes']/correction_area/the_sim\n",
    "    \n",
    "    # remove absorption line\n",
    "    xcut1=758\n",
    "    xcut2=767\n",
    "    xcut3=925\n",
    "    xcut4=970\n",
    "    \n",
    "    index_to_remove=np.where(np.logical_or(np.logical_and(the_wl>xcut1,the_wl<xcut2),np.logical_and(the_wl>xcut3,the_wl<xcut4)))[0]\n",
    "    \n",
    "                             \n",
    "    new_the_wl = the_wl[~np.isin(np.arange(the_wl.size), index_to_remove)]\n",
    "    new_ratio = ratio[~np.isin(np.arange(ratio.size), index_to_remove)]\n",
    "    \n",
    "    f_ratio = interpolate.interp1d(new_the_wl,new_ratio,bounds_error=False,fill_value=\"extrapolate\")\n",
    "    ratio_interp =f_ratio(WL)\n",
    "    \n",
    "                                \n",
    "    ax.plot(WL,ratio_interp,'.',color=\"purple\")\n",
    "\n",
    "    span=30\n",
    "    ratio_filtered = smooth_data_np_convolve(ratio_interp,span)\n",
    "    ax.plot(WL,ratio_filtered,'k-',lw=3)\n",
    "    \n",
    "    \n",
    "    dict_ratio[the_number] = ratio_filtered\n",
    "    array_ratio[idx,:] = ratio_filtered\n",
    "    \n",
    "    ax.axvline(x=758,linewidth=2,linestyle=\":\" ,color='r')\n",
    "    ax.axvline(x=767,linewidth=2,linestyle=':', color='r')\n",
    "    \n",
    "    ax.axvline(x=930,linewidth=2,linestyle=\":\" ,color='r')\n",
    "    ax.axvline(x=970,linewidth=2,linestyle=':', color='r')\n",
    "\n",
    "    ax.grid()\n",
    "    ax.set_ylim(0,2)\n",
    "    ax.set_ylabel(\"ratio data/sim\")\n",
    "    \n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do the fit\n",
    "\n",
    "https://hernandis.me/2020/04/05/three-examples-of-nonlinear-least-squares-fitting-in-python-with-scipy.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 2\n",
    "the_df=all_spectra[idx]\n",
    "data = the_df['all_fluxes']/correction_area\n",
    "dataerr = the_df[\"all_fluxes_err\"]/correction_area\n",
    "data_the_wl = the_df[\"all_lambdas\"].values\n",
    "\n",
    "index_sel= np.where(np.logical_and(data_the_wl>WLMINSEL,data_the_wl<WLMAXSEL))[0]\n",
    "\n",
    "data = data[index_sel].values\n",
    "dataerr = dataerr[index_sel].values \n",
    "data_the_wl = data_the_wl[index_sel]\n",
    "                    \n",
    "data_airmassvalue = infos.iloc[idx][\"spec_header_airmass\"]\n",
    "data_target = infos.iloc[idx][\"spec_target_label\"]\n",
    "f_sed = dict_f_sed[data_target] \n",
    "data_the_sedxthroughput = f_sed(data_the_wl) * f_thr_new(data_the_wl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwv0 = 3.0\n",
    "oz0 = 300.\n",
    "params0 = np.array([1,pwv0,oz0],dtype=object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MyFitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myFitter = FitAtmosphericParams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myres,myfit=myFitter.fit_greypwvo3(params0,data_the_wl,data,dataerr,data_airmassvalue,data_the_sedxthroughput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myfit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop on fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract spectrum from data\n",
    "dict_fit1 = OrderedDict()  # full range wavelength fit\n",
    "dict_fit2 = OrderedDict()  # Fit PWV : 850-1000 nm\n",
    "dict_fit3 = OrderedDict()  # Fit PWV : 800-850 nm\n",
    "dict_fit4 = OrderedDict()  # Fit PWV : 700-750 nm\n",
    "\n",
    "\n",
    "\n",
    "# H2O(900) band selection\n",
    "wlh2omin2 = 850\n",
    "wlh2omax2 = 1000\n",
    "dwlh2o2 = wlh2omax2-wlh2omin2\n",
    "\n",
    "# H2O(800) band selection\n",
    "wlh2omin3 = 780\n",
    "wlh2omax3 = 855\n",
    "dwlh2o3 = wlh2omax3-wlh2omin3\n",
    "\n",
    "# H2O(700) band selection\n",
    "wlh2omin4 = 695\n",
    "wlh2omax4 = 755\n",
    "dwlh2o4 = wlh2omax3-wlh2omin4\n",
    "\n",
    "\n",
    "\n",
    "# fit 1 : initial values for the parameters\n",
    "pwv0 = 4.0\n",
    "oz0 = 300.\n",
    "params0 = np.array([1,pwv0,oz0],dtype=object)\n",
    "\n",
    "# fit 2 : initial values for the parameters\n",
    "pwv0 = 4.0\n",
    "params1 = np.array([1,pwv0],dtype=object)\n",
    "\n",
    "\n",
    "# loop on all spectra\n",
    "for idx in range(NBSPECTRA):\n",
    "    \n",
    "    ####################################################################\n",
    "    ## Two Figures \n",
    "    #####################################################################\n",
    "    fig=plt.figure(figsize=(16,14))\n",
    "    gs = gridspec.GridSpec(2, 1,height_ratios=[4,1] ,figure=fig)\n",
    "\n",
    "    ####################################################################\n",
    "    ## Figure 1\n",
    "    #####################################################################\n",
    "    ax=fig.add_subplot(gs[0,0])\n",
    "    \n",
    "    \n",
    "    the_df=all_spectra[idx]\n",
    "    data = the_df['all_fluxes']/correction_area\n",
    "    dataerr = the_df[\"all_fluxes_err\"]/correction_area\n",
    "    data_the_wl = the_df[\"all_lambdas\"].values\n",
    "\n",
    "    index_sel= np.where(np.logical_and(data_the_wl>WLMINSEL,data_the_wl<WLMAXSEL))[0]\n",
    "\n",
    "    data = data[index_sel].values\n",
    "    dataerr = dataerr[index_sel].values \n",
    "    data_the_wl = data_the_wl[index_sel]\n",
    "                    \n",
    "    data_airmassvalue = infos.iloc[idx][\"spec_header_airmass\"]\n",
    "    data_target = infos.iloc[idx][\"spec_target_label\"]\n",
    "    data_number = infos.iloc[idx][\"number\"]\n",
    "    \n",
    "    f_sed = dict_f_sed[data_target] \n",
    "    data_the_sedxthroughput = f_sed(data_the_wl) * f_thr_new(data_the_wl)\n",
    "\n",
    "    label_airmass = f\" {data_target}({data_number}) : z = {data_airmassvalue:.2f}\"\n",
    "    \n",
    "    print(f\"======================================= {idx} :{label_airmass} =================================\")\n",
    "    \n",
    "    \n",
    "    ## 1st Fit on the whole range : Compute the fit of the parameters (alpha,pwv,oz)\n",
    "    myres,myfit=myFitter.fit_greypwvo3(params0,data_the_wl,data,dataerr,data_airmassvalue,data_the_sedxthroughput)\n",
    "    \n",
    "    alpha_fit,pwv_fit,oz_fit = myfit[\"popt\"]\n",
    "    greye,pwve,oze = myfit[\"sigmas\"]\n",
    "    \n",
    "    chi2 = myfit[\"chi2\"]\n",
    "    chi2_per_deg = myfit[\"chi2_per_deg\"]\n",
    "    \n",
    "    # sub dict\n",
    "    dict_infofit1 = {}\n",
    "    dict_infofit1[\"params\"] = myfit[\"popt\"]\n",
    "    dict_infofit1[\"eparams\"] = myfit[\"sigmas\"]\n",
    "    dict_infofit1[\"chi2perdeg\"] = myfit[\"chi2_per_deg\"]\n",
    "    \n",
    "   \n",
    "    \n",
    "    label_fit1 =f\"fit(350-1000nm) (chi2/Ndeg = {chi2_per_deg:.0f} ): pwv = {pwv_fit:.2f} +/- {pwve:.2f} mm, ozone = {oz_fit:.1f} +/- {oze:.1f} , grey-fact = {alpha_fit:.2f} +/- {greye:.2f}\" \n",
    "    # Compute the prediction\n",
    "    the_model1 = myFitter.pred_greypwvo3(myfit[\"popt\"],data_the_wl,data_airmassvalue,data_the_sedxthroughput)\n",
    "   \n",
    "\n",
    "    ## 2nd Fit on PWV in H2O(900) Compute the fit of the parameters (alpha,pwv)\n",
    "    \n",
    "    indexes_lwselection2 = np.where(np.logical_and(data_the_wl > wlh2omin2 , data_the_wl < wlh2omax2))[0]\n",
    "    data_the_wl2 = data_the_wl[indexes_lwselection2]\n",
    "    data2 = data[indexes_lwselection2]\n",
    "    dataerr2 = dataerr[indexes_lwselection2]\n",
    "    data_the_sedxthroughput2 = data_the_sedxthroughput[indexes_lwselection2]\n",
    "      \n",
    "    myres2,myfit2=myFitter.fit_greypwv(params1,data_the_wl2,data2,dataerr2,data_airmassvalue,data_the_sedxthroughput2)\n",
    "      \n",
    "    alpha_fit2,pwv_fit2 = myfit2[\"popt\"]\n",
    "    greye2,pwve2 = myfit2[\"sigmas\"]\n",
    "    \n",
    "    chi22 = myfit2[\"chi2\"]\n",
    "    chi22_per_deg = myfit2[\"chi2_per_deg\"]\n",
    "    \n",
    "    # sub dict\n",
    "    dict_infofit2 = {}\n",
    "    dict_infofit2[\"params\"] = myfit2[\"popt\"]\n",
    "    dict_infofit2[\"eparams\"] = myfit2[\"sigmas\"]\n",
    "    dict_infofit2[\"chi2perdeg\"] = myfit2[\"chi2_per_deg\"]\n",
    "     \n",
    "    label_fit2 =f\"fit(850-1000nm) (chi2/Ndeg = {chi22_per_deg:.0f} ): pwv = {pwv_fit2:.2f} +/- {pwve2:.2f} mm, grey-fact = {alpha_fit2:.2f} +/- {greye2:.2f}\" \n",
    "    # Compute the prediction\n",
    "    the_model2 = myFitter.pred_greypwv(myfit2[\"popt\"],data_the_wl2,data_airmassvalue,data_the_sedxthroughput2)\n",
    "\n",
    "    \n",
    "    \n",
    "    ## 3rd Fit on PWV in H2O(800) Compute the fit of the parameters (alpha,pwv)\n",
    "    \n",
    "    indexes_lwselection3 = np.where(np.logical_and(data_the_wl > wlh2omin3 , data_the_wl < wlh2omax3))[0]\n",
    "    data_the_wl3 = data_the_wl[indexes_lwselection3]\n",
    "    data3 = data[indexes_lwselection3]\n",
    "    dataerr3 = dataerr[indexes_lwselection3]\n",
    "    data_the_sedxthroughput3 = data_the_sedxthroughput[indexes_lwselection3]\n",
    "      \n",
    "    myres3,myfit3=myFitter.fit_greypwv(params1,data_the_wl3,data3,dataerr3,data_airmassvalue,data_the_sedxthroughput3)\n",
    "      \n",
    "    alpha_fit3,pwv_fit3 = myfit3[\"popt\"]\n",
    "    greye3,pwve3 = myfit3[\"sigmas\"]\n",
    "    \n",
    "    chi23 = myfit3[\"chi2\"]\n",
    "    chi23_per_deg = myfit3[\"chi2_per_deg\"]\n",
    "    \n",
    "    # sub dict\n",
    "    dict_infofit3 = {}\n",
    "    dict_infofit3[\"params\"] = myfit3[\"popt\"]\n",
    "    dict_infofit3[\"eparams\"] = myfit3[\"sigmas\"]\n",
    "    dict_infofit3[\"chi2perdeg\"] = myfit3[\"chi2_per_deg\"]\n",
    "     \n",
    "    label_fit3 =f\"fit(800-850nm) (chi2/Ndeg = {chi23_per_deg:.0f} ): pwv = {pwv_fit3:.2f} +/- {pwve3:.2f} mm, grey-fact = {alpha_fit3:.2f} +/- {greye3:.2f}\" \n",
    "    # Compute the prediction\n",
    "    the_model3 = myFitter.pred_greypwv(myfit3[\"popt\"],data_the_wl3,data_airmassvalue,data_the_sedxthroughput3)\n",
    "\n",
    "    \n",
    "    ## 4th Fit on PWV in H2O(700) Compute the fit of the parameters (alpha,pwv)\n",
    "    \n",
    "    indexes_lwselection4 = np.where(np.logical_and(data_the_wl > wlh2omin4 , data_the_wl < wlh2omax4))[0]\n",
    "    data_the_wl4 = data_the_wl[indexes_lwselection4]\n",
    "    data4 = data[indexes_lwselection4]\n",
    "    dataerr4 = dataerr[indexes_lwselection4]\n",
    "    data_the_sedxthroughput4 = data_the_sedxthroughput[indexes_lwselection4]\n",
    "      \n",
    "    myres4,myfit4=myFitter.fit_greypwv(params1,data_the_wl4,data4,dataerr4,data_airmassvalue,data_the_sedxthroughput4)\n",
    "      \n",
    "    alpha_fit4,pwv_fit4 = myfit4[\"popt\"]\n",
    "    greye4,pwve4 = myfit4[\"sigmas\"]\n",
    "    \n",
    "    chi24 = myfit3[\"chi2\"]\n",
    "    chi24_per_deg = myfit4[\"chi2_per_deg\"]\n",
    "    \n",
    "    # sub dict\n",
    "    dict_infofit4 = {}\n",
    "    dict_infofit4[\"params\"] = myfit4[\"popt\"]\n",
    "    dict_infofit4[\"eparams\"] = myfit4[\"sigmas\"]\n",
    "    dict_infofit4[\"chi2perdeg\"] = myfit4[\"chi2_per_deg\"]\n",
    "     \n",
    "    label_fit4 =f\"fit(700-750nm) (chi2/Ndeg = {chi24_per_deg:.0f} ): pwv = {pwv_fit4:.2f} +/- {pwve4:.2f} mm, grey-fact = {alpha_fit4:.2f} +/- {greye4:.2f}\" \n",
    "    # Compute the prediction\n",
    "    the_model4 = myFitter.pred_greypwv(myfit4[\"popt\"],data_the_wl4,data_airmassvalue,data_the_sedxthroughput4)\n",
    "    \n",
    "    \n",
    "    ######\n",
    "    # plot\n",
    "    ######\n",
    "\n",
    "    ax.errorbar(data_the_wl,data,yerr=dataerr, fmt = '.',ms=5,color=\"b\",capsize = 0.01, ecolor=all_colors[ifile], elinewidth = .01,label=label_airmass)\n",
    "    ax.plot(data_the_wl,the_model1,'r-',label=label_fit1,lw=3)\n",
    "    ax.plot(data_the_wl2,the_model2,'g-',label=label_fit2,lw=5)\n",
    "    ax.plot(data_the_wl3,the_model3,'-',color=\"orange\",label=label_fit3,lw=5)\n",
    "    ax.plot(data_the_wl4,the_model4,'-',color=\"cyan\",label=label_fit4,lw=5)\n",
    "\n",
    "    ax.grid()\n",
    "    ax.set_xlabel(\"$\\lambda$ (nm)\")\n",
    "    ax.set_ylabel(\"flux (erg/sec/m$^2$/nm)\")\n",
    "    title=f\"Fit Obs Spectr from {data_target} at {SITE} ({DATE}) {spectractormode}\"\n",
    "    ax.set_title(title,fontsize=20,fontweight='bold')\n",
    "    #ax.plot(sed_w,sed_f,'k-',label=\"SED\")\n",
    "    #ax.plot(WL,sed_predicted_f,color='darkviolet',lw=4,label = \"predicted flux\")\n",
    "    ax.set_xlim( WLMINSEL  , WLMAXSEL  )\n",
    "    ymax_toplot = data.max()*1.4\n",
    "    ax.set_ylim(0,ymax_toplot)\n",
    "\n",
    "    ax.legend(loc=\"upper left\")\n",
    "    # draw abs lines\n",
    "    plotlines(ax,ypos=ymax_toplot/10.)\n",
    "    \n",
    "    #ax.axvline(x=758,linewidth=2,linestyle=\":\" ,color='purple')\n",
    "    #ax.axvline(x=767,linewidth=2,linestyle=':', color='purple')\n",
    "    \n",
    "    #ax.axvline(x=920,linewidth=2,linestyle=\":\" ,color='purple')\n",
    "    #ax.axvline(x=980,linewidth=2,linestyle=':', color='purple')\n",
    "    main_ax = ax\n",
    "    ###############################################################\n",
    "    # Figure 2 deviation of data/sim from a straight line\n",
    "    ################################################################\n",
    "    \n",
    "    ax=fig.add_subplot(gs[1,0], sharex=main_ax)\n",
    "\n",
    "    ### \n",
    "    flux_from_data_fullscale = data\n",
    "    flux_from_data_err_fullscale = dataerr\n",
    "    wl_fullscale = data_the_wl\n",
    "    ratio_fullscale = flux_from_data_fullscale/the_model1\n",
    "    ratio_err_fullscale = flux_from_data_err_fullscale/the_model1\n",
    "    \n",
    "    ###\n",
    "    flux_from_data_smallscale2 = data2\n",
    "    flux_from_data_err_smallscale2 = dataerr2\n",
    "    wl_smallscale2 = data_the_wl2 \n",
    "    ratio_smallscale2 = flux_from_data_smallscale2/the_model2\n",
    "    ratio_err_smallscale2 = flux_from_data_err_smallscale2/the_model2\n",
    "    ##\n",
    "    flux_from_data_smallscale3 = data3\n",
    "    flux_from_data_err_smallscale3 = dataerr3\n",
    "    wl_smallscale3 = data_the_wl3 \n",
    "    ratio_smallscale3 = flux_from_data_smallscale3/the_model3\n",
    "    ratio_err_smallscale3 = flux_from_data_err_smallscale3/the_model3\n",
    "    ##\n",
    "    flux_from_data_smallscale4 = data4\n",
    "    flux_from_data_err_smallscale4 = dataerr4\n",
    "    wl_smallscale4 = data_the_wl4 \n",
    "    ratio_smallscale4 = flux_from_data_smallscale4/the_model4\n",
    "    ratio_err_smallscale4 = flux_from_data_err_smallscale4/the_model4\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    I1 = np.trapz((ratio_fullscale [indexes_lwselection2]-1),wl_fullscale[indexes_lwselection2])/dwlh2o2\n",
    "    I1err2 = np.trapz(ratio_err_fullscale[indexes_lwselection2]**2,wl_fullscale[indexes_lwselection2])/dwlh2o2\n",
    "    I1err = np.sqrt(I1err2)\n",
    "    SNR1 = np.abs(I1/I1err)\n",
    "    label_I1 = f\"I1 = {I1:.4f} +/- {I1err:.4f} (SNR1 = {SNR1:.2f})\"\n",
    "    \n",
    "    I2 = np.trapz((ratio_smallscale2-1),wl_smallscale2)/dwlh2o2\n",
    "    I2err2 = np.trapz(ratio_err_smallscale2**2,wl_smallscale2)/dwlh2o2\n",
    "    I2err = np.sqrt(I2err2)\n",
    "    SNR2 = np.abs(I2/I2err)\n",
    "    label_I2 = f\"I2 = {I2:.4f} +/- {I2err:.4f} (SNR2 = {SNR2:.2f})\"\n",
    "    \n",
    "    I3 = np.trapz((ratio_smallscale3-1),wl_smallscale3)/dwlh2o3\n",
    "    I3err2 = np.trapz(ratio_err_smallscale3**2,wl_smallscale3)/dwlh2o3\n",
    "    I3err = np.sqrt(I3err2)\n",
    "    SNR3 = np.abs(I3/I3err)\n",
    "    label_I3 = f\"I3 = {I3:.4f} +/- {I3err:.4f} (SNR3 = {SNR3:.2f})\"\n",
    "    \n",
    "    \n",
    "    I3 = np.trapz((ratio_smallscale3-1),wl_smallscale3)/dwlh2o3\n",
    "    I3err2 = np.trapz(ratio_err_smallscale3**2,wl_smallscale3)/dwlh2o3\n",
    "    I3err = np.sqrt(I3err2)\n",
    "    SNR3 = np.abs(I3/I3err)\n",
    "    label_I3 = f\"I3 = {I3:.4f} +/- {I3err:.4f} (SNR3 = {SNR3:.2f})\"\n",
    "    \n",
    "    I4 = np.trapz((ratio_smallscale4-1),wl_smallscale4)/dwlh2o4\n",
    "    I4err2 = np.trapz(ratio_err_smallscale4**2,wl_smallscale4)/dwlh2o4\n",
    "    I4err = np.sqrt(I4err2)\n",
    "    SNR4 = np.abs(I4/I4err)\n",
    "    label_I4 = f\"I4 = {I4:.4f} +/- {I4err:.4f} (SNR4 = {SNR4:.2f})\"\n",
    "    \n",
    "    ax.errorbar(wl_fullscale,ratio_fullscale,yerr=ratio_err_fullscale,fmt = '.',ms=5,color=\"r\",capsize = 0.1, ecolor=\"r\", elinewidth = .3,label=label_I1)\n",
    "    ax.errorbar(wl_smallscale2,ratio_smallscale2,yerr=ratio_err_smallscale2,fmt = '.',ms=5,color=\"g\",capsize = 0.5, ecolor=\"g\", elinewidth = .3,label=label_I2)\n",
    "    ax.errorbar(wl_smallscale3,ratio_smallscale3,yerr=ratio_err_smallscale3,fmt = '.',ms=5,color=\"orange\",capsize = 0.5, ecolor=\"orange\", elinewidth = .3,label=label_I3)\n",
    "    ax.errorbar(wl_smallscale4,ratio_smallscale4,yerr=ratio_err_smallscale4,fmt = '.',ms=5,color=\"cyan\",capsize = 0.5, ecolor=\"cyan\", elinewidth = .3,label=label_I4)\n",
    "\n",
    "    \n",
    "    ax.set_ylim(0.8,1.2)\n",
    "    ax.set_xlabel(\"$\\lambda$ (nm)\")\n",
    "    ax.set_ylabel(\"ratio data/sim\")\n",
    "    ax.grid()\n",
    "    ax.legend(loc=\"upper left\")\n",
    "    \n",
    "    # save in a dictionnaries\n",
    "    dict_infofit1[\"SNR\"] = SNR1\n",
    "    dict_infofit2[\"SNR\"] = SNR2\n",
    "    dict_infofit3[\"SNR\"] = SNR3\n",
    "    dict_infofit4[\"SNR\"] = SNR4\n",
    "    \n",
    "    # main dict for fit 1\n",
    "    dict_fit1[data_number] = dict_infofit1\n",
    "    \n",
    "    # main dict for fit 2\n",
    "    dict_fit2[data_number] = dict_infofit2\n",
    "    \n",
    "    # main dict for fit 3\n",
    "    dict_fit3[data_number] = dict_infofit3\n",
    "    \n",
    "    # main dict for fit 4\n",
    "    dict_fit4[data_number] = dict_infofit4\n",
    "    \n",
    "    \n",
    "    plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Fits results in infos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fitatm1 = pd.DataFrame(columns=['number1', 'chi2_1','pwv_1', 'oz_1','grey_1','epwv_1' ,'eoz_1', 'egrey_1','SNR_1'])\n",
    "\n",
    "count = 0\n",
    "for key, value in dict_fit1.items():\n",
    "    df_fitatm1.loc[count] = [key, value[\"chi2perdeg\"], value[\"params\"][1],value[\"params\"][2],value[\"params\"][0],value[\"eparams\"][1],value[\"eparams\"][2],value[\"eparams\"][0],value[\"SNR\"] ]\n",
    "    count+=1\n",
    "\n",
    "df_fitatm1['number1'] = df_fitatm1['number1'].astype('int32')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fitatm1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fitatm2 = pd.DataFrame(columns=['number2', 'chi2_2','pwv_2','grey_2','epwv_2' , 'egrey_2','SNR_2'])\n",
    "\n",
    "count = 0\n",
    "for key, value in dict_fit1.items():\n",
    "    df_fitatm2.loc[count] = [key, value[\"chi2perdeg\"], value[\"params\"][1],value[\"params\"][0],value[\"eparams\"][1],value[\"eparams\"][0],value[\"SNR\"] ]\n",
    "    count+=1\n",
    "\n",
    "df_fitatm2['number2'] = df_fitatm2['number2'].astype('int32')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fitatm2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fitatm3 = pd.DataFrame(columns=['number3', 'chi2_3','pwv_3','grey_3','epwv_3' , 'egrey_3','SNR_3'])\n",
    "\n",
    "count = 0\n",
    "for key, value in dict_fit3.items():\n",
    "    df_fitatm3.loc[count] = [key, value[\"chi2perdeg\"], value[\"params\"][1],value[\"params\"][0],value[\"eparams\"][1],value[\"eparams\"][0],value[\"SNR\"] ]\n",
    "    count+=1\n",
    "\n",
    "df_fitatm3['number3'] = df_fitatm3['number3'].astype('int32')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fitatm3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fitatm4 = pd.DataFrame(columns=['number4', 'chi2_4','pwv_4','grey_4','epwv_4','egrey_4','SNR_4'])\n",
    "\n",
    "count = 0\n",
    "for key, value in dict_fit4.items():\n",
    "    df_fitatm4.loc[count] = [key, value[\"chi2perdeg\"], value[\"params\"][1],value[\"params\"][0],value[\"eparams\"][1],value[\"eparams\"][0],value[\"SNR\"] ]\n",
    "    count+=1\n",
    "\n",
    "df_fitatm4['number4'] = df_fitatm4['number4'].astype('int32')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fitatm4.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine infos and fits results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined = pd.concat([infos,df_fitatm1, df_fitatm2,df_fitatm3, df_fitatm4],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined.drop(columns=['number1', 'number2','number3','number4'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined['pwv_avg'] = df_combined.apply(lambda x: (x.pwv_1/x.epwv_1**2+\n",
    "                                                      x.pwv_2/x.epwv_2**2+\n",
    "                                                      x.pwv_3/x.epwv_3**2+\n",
    "                                                      x.pwv_4/x.epwv_4**2)/(\n",
    "                                                      1/x.epwv_1**2+ 1/x.epwv_2**2 + 1/x.epwv_3**2 + 1/x.epwv_4**2)\n",
    "                                           , axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_combined['pwv_sig'] = df_combined.apply(lambda x: np.sqrt(( (x.pwv_1-x.pwv_avg)**2/x.epwv_1**2+\n",
    "#                                                       (x.pwv_2-x.pwv_avg)**2/x.epwv_2**2+\n",
    "#                                                       (x.pwv_3-x.pwv_avg)**2/x.epwv_3**2+\n",
    "#                                                       (x.pwv_4-x.pwv_avg)**2/x.epwv_4**2)/(\n",
    "#                                                      1/x.epwv_1**2+ 1/x.epwv_2**2 + 1/x.epwv_3**2 + 1/x.epwv_4**2))\n",
    "#                                           , axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined['pwv_sig'] = df_combined.apply(lambda x: np.sqrt(( (x.pwv_1-x.pwv_avg)**2+\n",
    "                                                       (x.pwv_2-x.pwv_avg)**2+\n",
    "                                                       (x.pwv_3-x.pwv_avg)**2+\n",
    "                                                       (x.pwv_4-x.pwv_avg)**2)/(4)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined['pwv_sig']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_fit = f\"multifitparamatm-{DATE}-{filterdisperser}-{spectractormode}.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined.to_csv(filename_fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df_combined.dropna(axis=0)\n",
    "df =df[df[\"pwv_sig\"]<1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_datetime = [ Time(str_time).to_datetime() for str_time in df['spec_date_obs'] ]\n",
    "numbers = df['number'].values\n",
    "    \n",
    "pwv= df['pwv_avg'].values\n",
    "epwv= df['pwv_sig'].values\n",
    "     \n",
    "N= len(numbers)\n",
    "   \n",
    "\n",
    "# Create rectangle x coordinates\n",
    "startTime = all_datetime[0]\n",
    "endTime =  all_datetime[-1]\n",
    "\n",
    "# convert to matplotlib date representation\n",
    "start = mdates.date2num(startTime)\n",
    "end = mdates.date2num(endTime)\n",
    "width = end - start\n",
    "\n",
    "\n",
    "\n",
    "fig=plt.figure(figsize=(20,5))\n",
    "gs = gridspec.GridSpec(1, 2,width_ratios=[3,1],figure=fig)\n",
    "    \n",
    "ax= fig.add_subplot(gs[0,0])\n",
    "myFmt = mdates.DateFormatter('%H:%M')\n",
    "ax.xaxis.set_major_formatter(myFmt)\n",
    " \n",
    "\n",
    "y_shift= 1\n",
    "\n",
    "  \n",
    "ax.plot(all_datetime,pwv,'r:o',color=\"r\",lw=3)\n",
    "ax.errorbar(all_datetime,pwv,yerr=epwv,fmt='o',color=\"r\",ecolor=\"k\",lw=1,alpha=1)\n",
    "    \n",
    "ax.xaxis.set_major_formatter(myFmt)\n",
    "ax.xaxis.set_tick_params(rotation=45)\n",
    "ax.set_xlabel(\"time (UTC)\")\n",
    "ax.set_ylabel(\"pwv (mm)\")\n",
    "ax.set_ylim(pwv.min()-2*y_shift,pwv.max()+2*y_shift)\n",
    "    # Plot rectangle\n",
    "    #rect = plt.Rectangle((start, airmasses.min()-2*y_shift), width, airmasses.max()+ 2*y_shift, color='grey',alpha=0.3)\n",
    "    #ax2.add_patch(rect)   \n",
    "    #ax.invert_yaxis()\n",
    "ax.grid()\n",
    "ax.set_ylim(0.,10.)\n",
    "\n",
    "\n",
    "for index in range(N):\n",
    "    textstr= str(numbers[index])\n",
    "        \n",
    "    if index%2 == 0:\n",
    "        dy = y_shift\n",
    "    else:\n",
    "        dy = -y_shift\n",
    "            \n",
    "    ax.text(all_datetime[index], pwv[index] + dy , textstr,fontsize=14,fontweight=\"bold\",ha='center',color=\"b\" )\n",
    "    \n",
    "    \n",
    "    \n",
    "ax= fig.add_subplot(gs[0,1])\n",
    "ax.hist(pwv,bins=25,range=(0,10))\n",
    "ax.set_xlabel(\"pwv (mm)\")\n",
    "    \n",
    "mu = pwv.mean()\n",
    "median = np.median(pwv)\n",
    "sigma =pwv.std()\n",
    "    \n",
    "textstr = '\\n'.join((\n",
    "r'$\\mu=%.2f$ mm' % (mu, ),\n",
    "r'$\\mathrm{median}=%.2f$ mm' % (median, ),\n",
    "r'$\\sigma=%.2f$ mm' % (sigma, )))\n",
    "props = dict(boxstyle='round', facecolor='white', alpha=0.5)\n",
    "ax.text(0.55, 0.95, textstr, transform=ax.transAxes, fontsize=14,verticalalignment='top', bbox=props)\n",
    "\n",
    "    \n",
    "the_title=f\"PWV Obs Spectr at {SITE} ({DATE}) {spectractormode}\"   \n",
    "\n",
    "plt.suptitle(the_title,fontsize=\"20\",fontweight=\"bold\")\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
